{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.157334Z",
     "start_time": "2024-05-11T15:01:01.748106Z"
    }
   },
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import spacy \n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "import dataclasses\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "USE_CACHE_DICTS = True # set to False to recompute all dictionaries\n",
    "\n",
    "# # Read dictionary pkl file\n",
    "# with open('email_to_departments.pkl', 'rb') as fp:\n",
    "#     email_to_departments = pickle.load(fp)\n",
    "#     print('email_to_departments dictionary loaded from pkl file')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/maore/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 598
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.767303Z",
     "start_time": "2024-05-11T15:01:02.158816Z"
    }
   },
   "cell_type": "code",
   "source": "enron_df = pd.read_pickle('enron_students.pkl')",
   "outputs": [],
   "execution_count": 599
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.904957Z",
     "start_time": "2024-05-11T15:01:02.768028Z"
    }
   },
   "source": [
    "# data cleaning\n",
    "enron_df['To'] = enron_df['To'].fillna('')\n",
    "enron_df['From'] = enron_df['From'].fillna('')\n",
    "enron_df['X-From'] = enron_df['X-From'].fillna('')\n",
    "enron_df['X-To'] = enron_df['X-To'].fillna('')\n",
    "enron_df['X-cc'] = enron_df['X-cc'].fillna('')\n",
    "enron_df['X-bcc'] = enron_df['X-bcc'].fillna('')\n"
   ],
   "outputs": [],
   "execution_count": 600
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.909514Z",
     "start_time": "2024-05-11T15:01:02.906086Z"
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_emails(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # Regex to match email addresses\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    return re.findall(email_pattern, text)\n",
    "\n",
    "def extract_single_email_from_text(text):\n",
    "    emails = extract_emails(text)\n",
    "    if (len(emails) > 1):\n",
    "        print(f\"Multiple emails found in: {text}\")\n",
    "    elif len(emails) == 1:\n",
    "        return emails[0]\n",
    "    print(f\"Could not extract email from: {text}\")\n",
    "    return None\n",
    "\n",
    "def extract_sent_to_emails(text):\n",
    "    emails = extract_emails(text)\n",
    "    if len(emails) > 0:\n",
    "        return emails\n",
    "    return []\n",
    "\n",
    "def is_between_ect_and_ees(email_to_depart_dict, row, is_including_cc_bcc=False, additional_check=True):\n",
    "    sender_email = extract_single_email_from_text(row['From'])\n",
    "    if sender_email in email_to_depart_dict:\n",
    "        sender_department = email_to_depart_dict[sender_email]\n",
    "        if sender_department != 'ECT' and sender_department != 'EES':\n",
    "            return False\n",
    "        else:\n",
    "            if is_including_cc_bcc:\n",
    "                reciever_emails = extract_sent_to_emails(row['To']) + extract_sent_to_emails(row['X-To'])\n",
    "            else:\n",
    "                reciever_emails = extract_sent_to_emails(row['To']) + extract_sent_to_emails(row['X-To']) + extract_sent_to_emails(row['X-cc']) + extract_sent_to_emails(row['X-bcc'])\n",
    "            \n",
    "            for email in reciever_emails:\n",
    "                if email in email_to_depart_dict:\n",
    "                    reciever_department = email_to_depart_dict[email]\n",
    "\n",
    "                    if sender_department == 'ECT' and reciever_department == 'EES':\n",
    "                        return True\n",
    "                    elif sender_department == 'EES' and reciever_department == 'ECT':\n",
    "                        return True\n",
    "                    \n",
    "            if additional_check:\n",
    "                if 'ECT' in row['X-To']:\n",
    "                    if 'EES' in row['X-From']:\n",
    "                        return True\n",
    "                if 'EES' in row['X-To']:\n",
    "                    if 'ECT' in row['X-From']:\n",
    "                        return True\n",
    "      \n",
    "            return False\n",
    "    \n",
    "    else:\n",
    "        if additional_check:\n",
    "            if 'ECT' in row['X-To']:\n",
    "                if 'EES' in row['X-From']:\n",
    "                    return True\n",
    "            if 'EES' in row['X-To']:\n",
    "                if 'ECT' in row['X-From']:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 601
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.918666Z",
     "start_time": "2024-05-11T15:01:02.910322Z"
    }
   },
   "source": [
    "\n",
    "def build_dict():\n",
    "    email_to_departments = {}\n",
    "    email_to_departments.update({\n",
    "            'smith.day@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'stuart.zisman@enron.com' : 'ECT'\n",
    "            ,'melissa.murphy@enron.com' : 'ECT'\n",
    "            ,'thresa.allen@enron.com' : 'ECT'\n",
    "            ,'leslie.reeves@enron.com' : 'ECT'\n",
    "            ,'stacey.white@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'brad.nebergall@enron.com': 'ECT'\n",
    "            ,'colleen.koenig@enron.com': 'EES'\n",
    "            ,'john.kinser@enron.com': 'ECT'\n",
    "            ,'jeff.merola@enron.com': 'EES'\n",
    "            })\n",
    "    \n",
    "    email_to_departments.update({'eric.bass@enron.com': 'ECT'})\n",
    "\n",
    "    multiple_count = 0\n",
    "    for index, row in enron_df.iterrows():\n",
    "        x_emails = extract_emails(row['X-From'])\n",
    "        from_emails = set([mail.lower() for mail in (extract_emails(row['From']) + x_emails)])\n",
    "        to_emails = set([mail.lower() for mail in (extract_emails(row['To']) + extract_emails(row['X-To']))])\n",
    "        if len(from_emails) == 0:\n",
    "            continue\n",
    "        if len(from_emails) > 1:\n",
    "            from_emails = [mail for mail in from_emails if not mail.startswith('imceanotes')]\n",
    "            if len(from_emails) > 1 or len(from_emails) == 0:\n",
    "                multiple_count += 1\n",
    "\n",
    "        for email in from_emails:\n",
    "            email = email.lower()\n",
    "            if \"enron.com\" not in email and email not in email_to_departments:\n",
    "                email_to_departments.update({email: 'NA'})\n",
    "            else:\n",
    "                if email in email_to_departments and email_to_departments[email] != 'Other':\n",
    "                    continue\n",
    "                elif 'EES' in row['X-From']:\n",
    "                    email_to_departments.update({email: 'EES'})\n",
    "                    if len(to_emails) == 1:\n",
    "                        email_to_departments.update({list(to_emails)[0]: 'ECT'})\n",
    "                elif 'ECT' in row['X-From']:\n",
    "                    email_to_departments.update({email: 'ECT'})\n",
    "                    if len(to_emails) == 1:\n",
    "                        email_to_departments.update({list(to_emails)[0]: 'EES'})\n",
    "                else:\n",
    "                    email_to_departments.update({email: 'Other'})\n",
    "\n",
    "        # new addition - need to check\n",
    "        if len(to_emails) == 1:\n",
    "            if 'ECT' in row['X-To']:\n",
    "                email_to_departments.update({list(to_emails)[0]: 'ECT'})\n",
    "            elif 'EES' in row['X-To']:\n",
    "                email_to_departments.update({list(to_emails)[0]: 'EES'})\n",
    "\n",
    "    email_to_departments.update({\n",
    "            'smith.day@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'stuart.zisman@enron.com' : 'ECT'\n",
    "            ,'melissa.murphy@enron.com' : 'ECT'\n",
    "            ,'thresa.allen@enron.com' : 'ECT'\n",
    "            ,'leslie.reeves@enron.com' : 'ECT'\n",
    "            ,'stacey.white@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'brad.nebergall@enron.com': 'ECT'\n",
    "            ,'colleen.koenig@enron.com': 'EES'\n",
    "            ,'john.kinser@enron.com': 'ECT'\n",
    "            ,'jeff.merola@enron.com\t': 'EES'\n",
    "            ,'scott.mills@enron.com': 'ECT'\n",
    "            ,'marilyn.colbert@enron.com': 'ECT'\n",
    "            ,'molly.harris@enron.com': 'ECT'\n",
    "            ,'joseph.wagner@enron.com': 'ECT'\n",
    "            ,'stuart.zisman@enron.com,' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'stephanie.gardner@enron.com' : 'EES'\n",
    "\n",
    "            })\n",
    "    \n",
    "    return email_to_departments\n",
    "\n",
    "if USE_CACHE_DICTS:\n",
    "    email_to_department_dict = pickle.load(open('email_to_departments.pkl', 'rb'))\n",
    "else:\n",
    "    email_to_department_dict = build_dict()"
   ],
   "outputs": [],
   "execution_count": 602
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.920964Z",
     "start_time": "2024-05-11T15:01:02.919277Z"
    }
   },
   "source": [
    "len(email_to_department_dict)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20638"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 603
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.213634Z",
     "start_time": "2024-05-11T15:01:02.921457Z"
    }
   },
   "source": [
    "enron_df['is_between_ect_and_ees'] = enron_df.apply(lambda row: is_between_ect_and_ees(email_to_department_dict, row), axis=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not extract email from: u@d.h\n",
      "Could not extract email from: pep <performance.>\n"
     ]
    }
   ],
   "execution_count": 604
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.215880Z",
     "start_time": "2024-05-11T15:01:06.214310Z"
    }
   },
   "source": [
    "if 'cheryl.dudley@enron.com' in email_to_department_dict:\n",
    "    print('yes')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "execution_count": 605
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.484514Z",
     "start_time": "2024-05-11T15:01:06.216431Z"
    }
   },
   "source": [
    "# remove all spaces \n",
    "enron_df['violated_rules'] = enron_df['violated_rules'].apply(lambda x: x.replace(' ', ''))\n",
    "\n",
    "# apply split ',' on violated rules\n",
    "enron_df['violated_rules'] = enron_df['violated_rules'].apply(lambda x: x.split(',')) "
   ],
   "outputs": [],
   "execution_count": 606
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.636397Z",
     "start_time": "2024-05-11T15:01:06.486491Z"
    }
   },
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "enron_df_not_catched_1_1 = enron_df[(enron_df['is_between_ect_and_ees'] == False) & (enron_df['violated_rules'].apply(lambda x: '1.1' in x ) & (enron_df['X-To'].str.contains('ECT')))]\n",
    "enron_df_not_catched_1_1.head(10)\n",
    "# len(enron_df_not_catched_1_1)\n",
    "\n",
    "# print(is_between_ect_and_ees(test, enron_df_not_catched_1_1.iloc[0], False))\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         Date                      From  \\\n",
       "349726   Wed, 6 Jun 2001 13:03:00 -0700 (PDT)  randal.maffett@enron.com   \n",
       "498426  Thu, 10 May 2001 12:49:00 -0700 (PDT)      john.kiani@enron.com   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                        To  \\\n",
       "349726  don.schroeder@enron.com, patrick.danaher@enron.com, adam.metry@enron.com, \\n\\tsarah.mulholland@enron.com, bill.briggs@enron.com, \\n\\tgerald.nemec@enron.com, lisa.vitali@enron.com, bill.white@enron.com, \\n\\tjames.gough@enron.com, jim.goughary@enron.com, john.wilson@enron.com   \n",
       "498426                                                                                                                                                                                                                                                                  v.weldon@enron.com   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    X-To  \\\n",
       "349726  Don Schroeder <Don Schroeder/ENRON@enronXgate>, Patrick Danaher <Patrick Danaher/NA/Enron@Enron>, Adam Metry <Adam Metry/ENRON@enronXgate>, Sarah Mulholland <Sarah Mulholland/ENRON@enronXgate>, Bill F Briggs <Bill F Briggs/ENRON@enronXgate>, Gerald Nemec <Gerald Nemec/HOU/ECT@ECT>, Lisa Vitali <Lisa Vitali/ENRON@enronXgate>, White@ <White@/O==ENRON/OU==NA/CN==RECIPIENTS/CN==JWHITE7@EX@enronXgate>, Bill White <Bill White/LON/ECT@ECT>, James Gough <James Gough/Enron@EUEnronXgate>, Jim Goughary <Jim Goughary/ENRON@enronXgate>, John L Wilson <John L Wilson/ENRON@enronXgate>   \n",
       "498426                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   V Charles Weldon <V Charles Weldon/HOU/ECT@ECT>   \n",
       "\n",
       "                                                        X-From  \\\n",
       "349726  Randal Maffett <Randal Maffett/ENRON@enronXgate@ENRON>   \n",
       "498426          John Kiani <John Kiani/ENRON@enronXgate@ENRON>   \n",
       "\n",
       "                                                  X-cc X-bcc  \\\n",
       "349726  John L Nowlan <John L Nowlan/ENRON@enronXgate>         \n",
       "498426                                                         \n",
       "\n",
       "                          Subject  \\\n",
       "349726  Kurt Wipp trip to Houston   \n",
       "498426        Stagecoach Contract   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               email_body  \\\n",
       "349726  Kurt Wipp is a recent hire in our London office to focus on origination/mid-market opps.  Kurt joins us after 15+ yrs w/ Methanex.  I've asked him to spend next week or so in Houston introducing himself to all the traders, originators, finance, RAC, Legal, etc...  I have given him most of your names and he will probably be contacting you to try and set up some time to meet.  My assistant, Beth Ryan, may also be coordinating some of the meetings.  Please take time to visit w/ him, even if only briefly and help him better understand your markets, perspectives, goals and objectives.  It's important that in addition to Kurt developing an understanding of our business strategies/opportunities that he also develop and accelerate his \"Enron DNA.\"  Thanks in advance!   \n",
       "498426                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Charlie,\\n\\nHere is the Stagecoach contract that I promised you.  Let me know if you have any questions.\\n\\nRegards,\\n\\nJohn\\n\\n     \n",
       "\n",
       "       verdict violated_rules  is_between_ect_and_ees  \n",
       "349726   BLOCK          [1.1]                   False  \n",
       "498426   BLOCK          [1.1]                   False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>Subject</th>\n",
       "      <th>email_body</th>\n",
       "      <th>verdict</th>\n",
       "      <th>violated_rules</th>\n",
       "      <th>is_between_ect_and_ees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349726</th>\n",
       "      <td>Wed, 6 Jun 2001 13:03:00 -0700 (PDT)</td>\n",
       "      <td>randal.maffett@enron.com</td>\n",
       "      <td>don.schroeder@enron.com, patrick.danaher@enron.com, adam.metry@enron.com, \\n\\tsarah.mulholland@enron.com, bill.briggs@enron.com, \\n\\tgerald.nemec@enron.com, lisa.vitali@enron.com, bill.white@enron.com, \\n\\tjames.gough@enron.com, jim.goughary@enron.com, john.wilson@enron.com</td>\n",
       "      <td>Don Schroeder &lt;Don Schroeder/ENRON@enronXgate&gt;, Patrick Danaher &lt;Patrick Danaher/NA/Enron@Enron&gt;, Adam Metry &lt;Adam Metry/ENRON@enronXgate&gt;, Sarah Mulholland &lt;Sarah Mulholland/ENRON@enronXgate&gt;, Bill F Briggs &lt;Bill F Briggs/ENRON@enronXgate&gt;, Gerald Nemec &lt;Gerald Nemec/HOU/ECT@ECT&gt;, Lisa Vitali &lt;Lisa Vitali/ENRON@enronXgate&gt;, White@ &lt;White@/O==ENRON/OU==NA/CN==RECIPIENTS/CN==JWHITE7@EX@enronXgate&gt;, Bill White &lt;Bill White/LON/ECT@ECT&gt;, James Gough &lt;James Gough/Enron@EUEnronXgate&gt;, Jim Goughary &lt;Jim Goughary/ENRON@enronXgate&gt;, John L Wilson &lt;John L Wilson/ENRON@enronXgate&gt;</td>\n",
       "      <td>Randal Maffett &lt;Randal Maffett/ENRON@enronXgate@ENRON&gt;</td>\n",
       "      <td>John L Nowlan &lt;John L Nowlan/ENRON@enronXgate&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Kurt Wipp trip to Houston</td>\n",
       "      <td>Kurt Wipp is a recent hire in our London office to focus on origination/mid-market opps.  Kurt joins us after 15+ yrs w/ Methanex.  I've asked him to spend next week or so in Houston introducing himself to all the traders, originators, finance, RAC, Legal, etc...  I have given him most of your names and he will probably be contacting you to try and set up some time to meet.  My assistant, Beth Ryan, may also be coordinating some of the meetings.  Please take time to visit w/ him, even if only briefly and help him better understand your markets, perspectives, goals and objectives.  It's important that in addition to Kurt developing an understanding of our business strategies/opportunities that he also develop and accelerate his \"Enron DNA.\"  Thanks in advance!</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498426</th>\n",
       "      <td>Thu, 10 May 2001 12:49:00 -0700 (PDT)</td>\n",
       "      <td>john.kiani@enron.com</td>\n",
       "      <td>v.weldon@enron.com</td>\n",
       "      <td>V Charles Weldon &lt;V Charles Weldon/HOU/ECT@ECT&gt;</td>\n",
       "      <td>John Kiani &lt;John Kiani/ENRON@enronXgate@ENRON&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Stagecoach Contract</td>\n",
       "      <td>Charlie,\\n\\nHere is the Stagecoach contract that I promised you.  Let me know if you have any questions.\\n\\nRegards,\\n\\nJohn\\n\\n</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 607
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.640018Z",
     "start_time": "2024-05-11T15:01:06.636984Z"
    }
   },
   "source": [
    "def update_dict(enron_df_not_catched_1_1, email_to_depart):\n",
    "    # iterate over the rows of the dataframe enron_df_not_catched_1_1\n",
    "    updated = 0\n",
    "    for index, row in enron_df_not_catched_1_1.iterrows():\n",
    "        x_emails = extract_emails(row['X-From'])\n",
    "        emails = set([mail.lower() for mail in (extract_emails(row['From']) + x_emails)])\n",
    "        sent_to_emails = extract_sent_to_emails(row['To']) + extract_sent_to_emails(row['X-To'])\n",
    "        if len(emails) == 0:\n",
    "            continue\n",
    "        if len(emails) > 1:\n",
    "            emails = [mail for mail in emails if not mail.startswith('imceanotes')]\n",
    "            if len(emails) > 1 or len(emails) == 0:\n",
    "                # print(f\"From: {row['From']} X-From: {row['X-From']} has multiple emails: {emails}\")\n",
    "                continue\n",
    "        for email in emails:\n",
    "            email = email.lower()\n",
    "            # if from email is in dictionary, get the department\n",
    "            if email in email_to_depart:\n",
    "                depart = email_to_depart[email]\n",
    "                if depart == 'ECT':\n",
    "                    if len(sent_to_emails) == 1:\n",
    "                        email_to_depart[sent_to_emails[0]] = 'EES'\n",
    "                        updated += 1\n",
    "                elif depart == 'EES':\n",
    "                    if len(sent_to_emails) == 1:\n",
    "                        email_to_depart[sent_to_emails[0]] = 'ECT'\n",
    "                        updated += 1\n",
    "\n",
    "    print(f\"Updated {updated} emails\")\n",
    "    \n",
    "\n",
    "\n",
    "update_dict(enron_df_not_catched_1_1, email_to_department_dict)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 0 emails\n"
     ]
    }
   ],
   "execution_count": 608
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HERE WE START USER TO LOCATION *\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.644746Z",
     "start_time": "2024-05-11T15:01:06.640649Z"
    }
   },
   "source": [
    "def get_email_to_location_dict(df):\n",
    "    email_to_location = {}\n",
    "    for index, row in enron_df.iterrows():\n",
    "        x_emails = extract_emails(row['X-From'])\n",
    "        from_emails = set([mail.lower() for mail in (extract_emails(row['From']) + x_emails)])\n",
    "        if '/OU=EU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'EU'})\n",
    "        elif '/HOU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "        elif '/OU=NA/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "\n",
    "    # iterate over the dataframe to get \n",
    "    violated_rule_1_2 = df[df['violated_rules'].apply(lambda x: '1.2' in x)]\n",
    "\n",
    "    for index, row in violated_rule_1_2.iterrows():\n",
    "        from_emails = extract_emails(row['X-From'])\n",
    "        from_emails = list(set([mail.lower() for mail in (extract_emails(row['From']) + from_emails)]))\n",
    "        if '/OU=EU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'EU'})\n",
    "        elif '/HOU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "        elif '/OU=NA/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "        \n",
    "        sent_to_email = extract_emails(row['X-To'])\n",
    "        if len(sent_to_email) == 1:\n",
    "            if from_emails[0] not in email_to_location:\n",
    "                continue\n",
    "            if email_to_location[from_emails[0]] == 'EU':\n",
    "                email_to_location.update({sent_to_email[0]: 'NA'})\n",
    "            elif email_to_location[from_emails[0]] == 'NA':\n",
    "                email_to_location.update({sent_to_email[0]: 'EU'})\n",
    "            \n",
    "    return email_to_location\n",
    "\n",
    "if USE_CACHE_DICTS:\n",
    "    email_to_location = pickle.load(open('email_to_location.pkl', 'rb'))\n",
    "else:\n",
    "    email_to_location = get_email_to_location_dict(enron_df)"
   ],
   "outputs": [],
   "execution_count": 609
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.647356Z",
     "start_time": "2024-05-11T15:01:06.645336Z"
    }
   },
   "source": [
    "def is_between_EU_and_NA(row, email_to_location):\n",
    "    from_email = extract_emails(row['From'])\n",
    "    from_email = extract_emails(row['X-From']) + from_email\n",
    "    from_email = list(set([mail.lower() for mail in from_email]))\n",
    "    to_email = extract_emails(row['To'])\n",
    "    to_email = extract_emails(row['X-To']) + to_email\n",
    "    to_email = list(set([mail.lower() for mail in to_email]))\n",
    "    if len(from_email) == 0 or len(to_email) == 0:\n",
    "        return False\n",
    "    if from_email[0] in email_to_location:\n",
    "        if email_to_location[from_email[0]] == 'EU':\n",
    "            for email in to_email:\n",
    "                if email in email_to_location and email_to_location[email] == 'NA':\n",
    "                    return True\n",
    "        if email_to_location[from_email[0]] == 'NA':\n",
    "            for email in to_email:\n",
    "                if email in email_to_location and email_to_location[email] == 'EU':\n",
    "                    return True\n",
    "    \n",
    "    return False"
   ],
   "outputs": [],
   "execution_count": 610
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.842986Z",
     "start_time": "2024-05-11T15:01:06.647925Z"
    }
   },
   "source": [
    "enron_df['is_EU_To_NA'] = enron_df.apply(lambda row: is_between_EU_and_NA(row, email_to_location), axis=1)"
   ],
   "outputs": [],
   "execution_count": 611
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.889621Z",
     "start_time": "2024-05-11T15:01:11.843583Z"
    }
   },
   "source": [
    "not_working = enron_df[(enron_df['is_EU_To_NA'] == False) & (enron_df['violated_rules'].apply(lambda x: '1.2' in x))]\n",
    "not_working.head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        Date                      From  \\\n",
       "4207    Mon, 4 Dec 2000 23:08:00 -0800 (PST)     craig.brown@enron.com   \n",
       "4790   Tue, 12 Dec 2000 11:33:00 -0800 (PST)      eric.letke@enron.com   \n",
       "7899   Tue, 12 Dec 2000 11:33:00 -0800 (PST)      eric.letke@enron.com   \n",
       "7929    Mon, 4 Dec 2000 23:08:00 -0800 (PST)     craig.brown@enron.com   \n",
       "12190   Mon, 4 Dec 2000 08:19:00 -0800 (PST)      bryan.hull@enron.com   \n",
       "15572   Mon, 4 Dec 2000 08:19:00 -0800 (PST)      bryan.hull@enron.com   \n",
       "18070  Thu, 10 May 2001 02:41:00 -0700 (PDT)      bryan.hull@enron.com   \n",
       "18918  Thu, 10 May 2001 02:41:00 -0700 (PDT)      bryan.hull@enron.com   \n",
       "19169  Thu, 10 May 2001 12:41:00 -0700 (PDT)      bryan.hull@enron.com   \n",
       "19432  Mon, 12 Nov 2001 07:44:35 -0800 (PST)  daniel.muschar@enron.com   \n",
       "\n",
       "                                                                                                                                  To  \\\n",
       "4207                                                                                                           heidi.smith@enron.com   \n",
       "4790                                                                          jennifer.medcalf@enron.com, william.bradford@enron.com   \n",
       "7899                                                                          jennifer.medcalf@enron.com, william.bradford@enron.com   \n",
       "7929                                                                                                           heidi.smith@enron.com   \n",
       "12190                                                                                                            luis.mena@enron.com   \n",
       "15572                                                                                                            luis.mena@enron.com   \n",
       "18070  don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com   \n",
       "18918  don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com   \n",
       "19169  don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com   \n",
       "19432                                                              don.baughman@enron.com, jae.black@enron.com, lloyd.will@enron.com   \n",
       "\n",
       "                                                                                                                                                                                                                                     X-To  \\\n",
       "4207                                                                                                                                                                                                                          Heidi Smith   \n",
       "4790                                                                                                                                                                                                 Jennifer Medcalf, William S Bradford   \n",
       "7899                                                                                                                                                                                                 Jennifer Medcalf, William S Bradford   \n",
       "7929                                                                                                                                                                                                                          Heidi Smith   \n",
       "12190                                                                                                                                                                                                                           Luis Mena   \n",
       "15572                                                                                                                                                                                                                           Luis Mena   \n",
       "18070                                                                                                                                                           Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia   \n",
       "18918                                                                                                                                                           Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia   \n",
       "19169  Don Baughman <Don Baughman/HOU/ECT@ECT>, Juan Hernandez <Juan Hernandez/Corp/Enron@ENRON>, Rudy Acevedo <Rudy Acevedo/HOU/ECT@ECT>, Chad Starnes <Chad Starnes/Corp/Enron@Enron>, Miguel L Garcia <Miguel L Garcia/NA/Enron@ENRON>   \n",
       "19432                                                        Baughman Jr., Don </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dbaughm>, Black, Tamara Jae </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tblack>, Will, Lloyd </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lwill>   \n",
       "\n",
       "                                                          X-From  \\\n",
       "4207                                               Craig H Brown   \n",
       "4790                                                  Eric Letke   \n",
       "7899                                                  Eric Letke   \n",
       "7929                                               Craig H Brown   \n",
       "12190                                                 Bryan Hull   \n",
       "15572                                                 Bryan Hull   \n",
       "18070                                                 Bryan Hull   \n",
       "18918                                                 Bryan Hull   \n",
       "19169             Bryan Hull <Bryan Hull/ENRON@enronXgate@ENRON>   \n",
       "19432  Muschar, Daniel </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DMUSCHA>   \n",
       "\n",
       "                                                                            X-cc  \\\n",
       "4207                                           Jeff Youngflesh, Jennifer Medcalf   \n",
       "4790                        James M Wood, John Woodman, Greg Sharp, Robert Greer   \n",
       "7899                        James M Wood, John Woodman, Greg Sharp, Robert Greer   \n",
       "7929                                           Jeff Youngflesh, Jennifer Medcalf   \n",
       "12190  Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins   \n",
       "15572  Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins   \n",
       "18070                                                                              \n",
       "18918                                                                              \n",
       "19169                                                                              \n",
       "19432                                                                              \n",
       "\n",
       "      X-bcc            Subject  \\\n",
       "4207          Re: Vulcan Signs   \n",
       "4790             Urgent - Sony   \n",
       "7899             Urgent - Sony   \n",
       "7929          Re: Vulcan Signs   \n",
       "12190                  Re: FYI   \n",
       "15572                  Re: FYI   \n",
       "18070                 Rotation   \n",
       "18918                 Rotation   \n",
       "19169                 Rotation   \n",
       "19432        24 hr 1-800 phone   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    email_body  \\\n",
       "4207   Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...   \n",
       "4790                                                                                                                                                                                                                               Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?   \n",
       "7899                                                                                                                                                                                                                               Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?   \n",
       "7929   Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...   \n",
       "12190  You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...   \n",
       "15572  You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...   \n",
       "18070                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195   \n",
       "18918                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195   \n",
       "19169                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I want to thank all of you for taking the time to meet with me about the hourly desk trading position.  Unfortunately, I have to withdraw my name from consideration.  I have accepted a position working on the Texas Gas Trading desk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195   \n",
       "19432                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           TJ:\\n\\nHow many 1-800 phone numbers does power have? ( If any other than 24 Hr trading, please advise)\\nWhat is the number for 24 HR group? ( I will need to coordinate a cutover for this)\\nDo you know of any special phone needs for the weekend trading?  (The people on turrets will be fine, they pin in anywhere)\\n\\nAny other thoughts or concerns are appreciated.\\n\\nThank you,\\n\\nDaniel A. Muschar\\nECS Project Team Lead\\nOffice: 713-853-4344\\nCell: 281-541-6203\\ndaniel.muschar@enron.com\\nCCNA, MCSE, CNA, A+   \n",
       "\n",
       "      verdict violated_rules  is_between_ect_and_ees  is_EU_To_NA  \n",
       "4207    BLOCK     [1.2, 2.1]                   False        False  \n",
       "4790    BLOCK          [1.2]                   False        False  \n",
       "7899    BLOCK          [1.2]                   False        False  \n",
       "7929    BLOCK     [1.2, 2.1]                   False        False  \n",
       "12190   BLOCK          [1.2]                    True        False  \n",
       "15572   BLOCK          [1.2]                    True        False  \n",
       "18070   BLOCK     [1.2, 2.1]                   False        False  \n",
       "18918   BLOCK     [1.2, 2.1]                   False        False  \n",
       "19169   BLOCK     [1.2, 2.1]                   False        False  \n",
       "19432   BLOCK          [1.2]                   False        False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>Subject</th>\n",
       "      <th>email_body</th>\n",
       "      <th>verdict</th>\n",
       "      <th>violated_rules</th>\n",
       "      <th>is_between_ect_and_ees</th>\n",
       "      <th>is_EU_To_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>Mon, 4 Dec 2000 23:08:00 -0800 (PST)</td>\n",
       "      <td>craig.brown@enron.com</td>\n",
       "      <td>heidi.smith@enron.com</td>\n",
       "      <td>Heidi Smith</td>\n",
       "      <td>Craig H Brown</td>\n",
       "      <td>Jeff Youngflesh, Jennifer Medcalf</td>\n",
       "      <td></td>\n",
       "      <td>Re: Vulcan Signs</td>\n",
       "      <td>Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>Tue, 12 Dec 2000 11:33:00 -0800 (PST)</td>\n",
       "      <td>eric.letke@enron.com</td>\n",
       "      <td>jennifer.medcalf@enron.com, william.bradford@enron.com</td>\n",
       "      <td>Jennifer Medcalf, William S Bradford</td>\n",
       "      <td>Eric Letke</td>\n",
       "      <td>James M Wood, John Woodman, Greg Sharp, Robert Greer</td>\n",
       "      <td></td>\n",
       "      <td>Urgent - Sony</td>\n",
       "      <td>Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>Tue, 12 Dec 2000 11:33:00 -0800 (PST)</td>\n",
       "      <td>eric.letke@enron.com</td>\n",
       "      <td>jennifer.medcalf@enron.com, william.bradford@enron.com</td>\n",
       "      <td>Jennifer Medcalf, William S Bradford</td>\n",
       "      <td>Eric Letke</td>\n",
       "      <td>James M Wood, John Woodman, Greg Sharp, Robert Greer</td>\n",
       "      <td></td>\n",
       "      <td>Urgent - Sony</td>\n",
       "      <td>Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>Mon, 4 Dec 2000 23:08:00 -0800 (PST)</td>\n",
       "      <td>craig.brown@enron.com</td>\n",
       "      <td>heidi.smith@enron.com</td>\n",
       "      <td>Heidi Smith</td>\n",
       "      <td>Craig H Brown</td>\n",
       "      <td>Jeff Youngflesh, Jennifer Medcalf</td>\n",
       "      <td></td>\n",
       "      <td>Re: Vulcan Signs</td>\n",
       "      <td>Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12190</th>\n",
       "      <td>Mon, 4 Dec 2000 08:19:00 -0800 (PST)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>luis.mena@enron.com</td>\n",
       "      <td>Luis Mena</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td>Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins</td>\n",
       "      <td></td>\n",
       "      <td>Re: FYI</td>\n",
       "      <td>You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15572</th>\n",
       "      <td>Mon, 4 Dec 2000 08:19:00 -0800 (PST)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>luis.mena@enron.com</td>\n",
       "      <td>Luis Mena</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td>Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins</td>\n",
       "      <td></td>\n",
       "      <td>Re: FYI</td>\n",
       "      <td>You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18070</th>\n",
       "      <td>Thu, 10 May 2001 02:41:00 -0700 (PDT)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com</td>\n",
       "      <td>Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rotation</td>\n",
       "      <td>I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18918</th>\n",
       "      <td>Thu, 10 May 2001 02:41:00 -0700 (PDT)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com</td>\n",
       "      <td>Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rotation</td>\n",
       "      <td>I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19169</th>\n",
       "      <td>Thu, 10 May 2001 12:41:00 -0700 (PDT)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com</td>\n",
       "      <td>Don Baughman &lt;Don Baughman/HOU/ECT@ECT&gt;, Juan Hernandez &lt;Juan Hernandez/Corp/Enron@ENRON&gt;, Rudy Acevedo &lt;Rudy Acevedo/HOU/ECT@ECT&gt;, Chad Starnes &lt;Chad Starnes/Corp/Enron@Enron&gt;, Miguel L Garcia &lt;Miguel L Garcia/NA/Enron@ENRON&gt;</td>\n",
       "      <td>Bryan Hull &lt;Bryan Hull/ENRON@enronXgate@ENRON&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rotation</td>\n",
       "      <td>I want to thank all of you for taking the time to meet with me about the hourly desk trading position.  Unfortunately, I have to withdraw my name from consideration.  I have accepted a position working on the Texas Gas Trading desk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19432</th>\n",
       "      <td>Mon, 12 Nov 2001 07:44:35 -0800 (PST)</td>\n",
       "      <td>daniel.muschar@enron.com</td>\n",
       "      <td>don.baughman@enron.com, jae.black@enron.com, lloyd.will@enron.com</td>\n",
       "      <td>Baughman Jr., Don &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dbaughm&gt;, Black, Tamara Jae &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tblack&gt;, Will, Lloyd &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lwill&gt;</td>\n",
       "      <td>Muschar, Daniel &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=DMUSCHA&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>24 hr 1-800 phone</td>\n",
       "      <td>TJ:\\n\\nHow many 1-800 phone numbers does power have? ( If any other than 24 Hr trading, please advise)\\nWhat is the number for 24 HR group? ( I will need to coordinate a cutover for this)\\nDo you know of any special phone needs for the weekend trading?  (The people on turrets will be fine, they pin in anywhere)\\n\\nAny other thoughts or concerns are appreciated.\\n\\nThank you,\\n\\nDaniel A. Muschar\\nECS Project Team Lead\\nOffice: 713-853-4344\\nCell: 281-541-6203\\ndaniel.muschar@enron.com\\nCCNA, MCSE, CNA, A+</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 612
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.891803Z",
     "start_time": "2024-05-11T15:01:11.890299Z"
    }
   },
   "source": [
    "print(len(email_to_location))\n",
    "# enron_df.head(10)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3985\n"
     ]
    }
   ],
   "execution_count": 613
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.895526Z",
     "start_time": "2024-05-11T15:01:11.892466Z"
    }
   },
   "source": [
    "def get_c_suit_dict():\n",
    "    emails = set({\n",
    "        'kenneth.lay@enron.com',\n",
    "        'ken.skilling@enron.com',\n",
    "        'rbowers@nyiso.com',\n",
    "        'michael.brown@enron.com',\n",
    "        'john.sherriff@enron.com',\n",
    "        'jeffrey.sherrick@enron.com',\n",
    "        'a..shankman@enron.com',\n",
    "        'ken.rice@enron.com',\n",
    "        'greg.piper@enron.com',\n",
    "        'mark.metts@enron.com',\n",
    "        'coo.jeff@enron.com',\n",
    "        'rebecca.mcdonald@enron.com',\n",
    "        'danny.mccarty@enron.com',\n",
    "        'dan.leff@enron.com',\n",
    "        'john.lavorato@enron.com',\n",
    "        'mark.koenig@enron.com',\n",
    "        'louise.kitchen@enron.com',\n",
    "        'stanley.horton@enron.com',\n",
    "        '40enron@enron.com', # for some reason is tagged for stanley horton\n",
    "        'ben.glisan@enron.com',\n",
    "        'mark.frevert@enron.com',\n",
    "        'andrew.fastow@enron.com',\n",
    "        'jr..legal@enron.com',\n",
    "        'derrick@enron.com',\n",
    "        'david.delainey@enron.com',\n",
    "        'richard.causey@enron.com',\n",
    "        'michael.brown@enron.com',\n",
    "        'raymond.bowen@enron.com',\n",
    "    })\n",
    "\n",
    "    violated_rule_1_3 = enron_df[enron_df['violated_rules'].apply(lambda x: '2.2' in x)]\n",
    "\n",
    "    for index, row in violated_rule_1_3.iterrows():\n",
    "        from_emails = extract_emails(row['X-From'])\n",
    "        from_emails = list(set([mail.lower() for mail in (extract_emails(row['From']) + from_emails)]))\n",
    "        to_email = extract_emails(row['To'])\n",
    "        to_email = extract_emails(row['X-To']) + to_email\n",
    "        to_email = list(set([mail.lower() for mail in to_email]))\n",
    "\n",
    "        if len(from_emails) == 0:\n",
    "            continue\n",
    "        for email in from_emails:\n",
    "            emails.add(email)\n",
    "            # print(f\"Email: {email} is in C-Suit\")\n",
    "\n",
    "        # for email in to_email:\n",
    "        #     emails.add(email)\n",
    "        #     print(f\"Email: {email} is in C-Suit\")\n",
    "\n",
    "    return emails\n",
    "\n",
    "if USE_CACHE_DICTS:\n",
    "    c_suit_emails = pickle.load(open('c_suit_emails.pkl', 'rb'))\n",
    "else:\n",
    "    c_suit_emails = get_c_suit_dict()"
   ],
   "outputs": [],
   "execution_count": 614
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.897868Z",
     "start_time": "2024-05-11T15:01:11.896027Z"
    }
   },
   "source": [
    "def is_in_c_suit(row, c_suit_emails):\n",
    "    # Extract and clean email addresses from 'From' fields\n",
    "    from_emails = extract_emails(row['X-From']) + extract_emails(row['From'])\n",
    "    from_emails = list(set(email.lower() for email in from_emails))\n",
    "\n",
    "    # Extract and clean email addresses from 'To' fields\n",
    "    to_email = extract_emails(row['X-To']) + extract_emails(row['To'])\n",
    "    to_email = list(set(email.lower() for email in to_email))\n",
    "\n",
    "    # Check if both sender and recipient are in the c-suite email list\n",
    "    return any(email in c_suit_emails for email in from_emails) and any(email in c_suit_emails for email in to_email)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 615
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.192452Z",
     "start_time": "2024-05-11T15:01:11.898421Z"
    }
   },
   "source": [
    "enron_df['is_c_suit'] = enron_df.apply(lambda row: is_in_c_suit(row, c_suit_emails), axis=1)"
   ],
   "outputs": [],
   "execution_count": 616
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.194554Z",
     "start_time": "2024-05-11T15:01:17.193217Z"
    }
   },
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ],
   "outputs": [],
   "execution_count": 617
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.196622Z",
     "start_time": "2024-05-11T15:01:17.195045Z"
    }
   },
   "source": [
    "def get_from_to_emails(row):\n",
    "    from_emails = extract_emails(row['X-From']) + extract_emails(row['From'])\n",
    "    from_emails = list(set(email.lower() for email in from_emails))\n",
    "\n",
    "    # Extract and clean email addresses from 'To' fields\n",
    "    to_email = extract_emails(row['X-To']) + extract_emails(row['To'])\n",
    "    to_email = list(set(email.lower() for email in to_email))\n",
    "\n",
    "    return from_emails, to_email"
   ],
   "outputs": [],
   "execution_count": 618
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.199726Z",
     "start_time": "2024-05-11T15:01:17.197225Z"
    }
   },
   "source": [
    "def is_leaving_corporate(row):\n",
    "    from_emails, to_email = get_from_to_emails(row)\n",
    "    if len(from_emails) == 0 or len(to_email) == 0:\n",
    "        return False\n",
    "    \n",
    "    for email in to_email:\n",
    "        if 'enron.com' not in email:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_leaving_ect(row, email_to_depart):\n",
    "    from_emails, to_email = get_from_to_emails(row)\n",
    "    if len(from_emails) == 0 or len(to_email) == 0:\n",
    "        return False\n",
    "\n",
    "    for email in from_emails:\n",
    "        if email in email_to_depart and email_to_depart[email] == 'ECT':\n",
    "            for t_email in to_email:\n",
    "                if t_email in email_to_depart and email_to_depart[t_email] != 'ECT':\n",
    "                    return True\n",
    "\n",
    "    return False"
   ],
   "outputs": [],
   "execution_count": 619
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.201948Z",
     "start_time": "2024-05-11T15:01:17.200249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save all dictionaries as pickle\n",
    "import pickle\n",
    "global USE_CACHE_DICTS\n",
    "if not USE_CACHE_DICTS:\n",
    "    pickle.dump(email_to_location, open('email_to_location.pkl', 'wb'))\n",
    "    pickle.dump(email_to_department_dict, open('email_to_departments.pkl', 'wb'))\n",
    "    pickle.dump(c_suit_emails, open('c_suit_emails.pkl', 'wb'))\n",
    "    print('All dictionaries saved as pickle')"
   ],
   "outputs": [],
   "execution_count": 620
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.204290Z",
     "start_time": "2024-05-11T15:01:17.202485Z"
    }
   },
   "source": [
    "class StaticAnalyzer:\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_1_1(row):\n",
    "        return is_between_ect_and_ees(email_to_department_dict, row, is_including_cc_bcc=False, additional_check=True)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_1_2(row):\n",
    "        return is_between_EU_and_NA(row, email_to_location)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_1_3(row):\n",
    "        return is_leaving_corporate(row)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_2_1(row):\n",
    "        return is_leaving_ect(row, email_to_department_dict)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_2_2(row):\n",
    "        return is_in_c_suit(row, c_suit_emails)\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_2_3(row):\n",
    "        return is_leaving_corporate(row)"
   ],
   "outputs": [],
   "execution_count": 621
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.207678Z",
     "start_time": "2024-05-11T15:01:17.204776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclasses.dataclass()\n",
    "class ContentAnalysisResult:\n",
    "    quids: []\n",
    "    piis: []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.quids = []\n",
    "        self.piis = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'(Sensitive: {len(self.piis) > 0 or len(self.quids) > 0} | Quids: {self.quids} | PII: {self.piis})'\n",
    "    \n",
    "    def is_sensitive(self, rule_id):\n",
    "        if rule_id == '2.3':\n",
    "            return len(self.piis) > 0 or len(self.quids) >= 2\n",
    "        else:\n",
    "            return len(self.piis) > 0 or len(self.quids) > 0\n",
    "\n",
    "@dataclasses.dataclass()\n",
    "class TopicAnalysisResult:\n",
    "    is_legal: bool = False\n",
    "    is_business: bool = False\n",
    "    is_finance: bool = False\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'(Legal: {self.is_legal} | Business: {self.is_business} | Finance: {self.is_finance})'\n",
    "    \n",
    "@dataclasses.dataclass()\n",
    "class EnforcerResult:\n",
    "    violated_rules: []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.violated_rules = []\n",
    "\n",
    "    def is_allowed(self)-> bool:\n",
    "        return len(self.violated_rules) == 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Violated Rules: {self.violated_rules}'\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 622
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.216617Z",
     "start_time": "2024-05-11T15:01:17.208251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_all_ssn(text):\n",
    "    return re.findall(r'\\d{3}-\\d{2}-\\d{4}', text)\n",
    "\n",
    "def find_all_credit_cards(text):\n",
    "    return re.findall(r'\\d{4}-\\d{4}-\\d{4}-\\d{4}', text) \n",
    "\n",
    "def find_all_phone_numbers(text):\n",
    "    return re.findall(r'\\(?\\d{3}\\)?\\s*-\\s*\\d{3}\\s*-\\s*\\d{4}', text) \n",
    "\n",
    "def find_sensitive_words(text):\n",
    "    return re.findall(r'password|attach|confidential', text.lower())\n",
    "\n",
    "\n",
    "class PII:\n",
    "    def __init__(self, entity_type, score, text):\n",
    "        self.entity_type = entity_type\n",
    "        self.score = score\n",
    "        self.text = text\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'(Entity: {self.entity_type} | Score: {self.score} | Text: {self.text})'\n",
    "        \n",
    "class ContentAnalyzer:\n",
    "    \n",
    "    MAX_DOC_SIZE_FOR_SPACY = 2000\n",
    "    QUIDS = ['ORG', 'GPE', 'LOW', 'FAC', 'LOC']\n",
    "    SENSITIVE = ['MONEY', 'PERCENT', 'NORP', 'PRODUCT', 'EVENT']\n",
    "    POTENTIALLY_SENSITIVE = ['DATE', 'TIME', 'QUANTITY', 'ORDINAL', 'CARDINAL', 'PERSON']\n",
    "    \n",
    "    def __init__(self, software='spacy'):      \n",
    "        self.software = software\n",
    "        if software == 'spacy':\n",
    "            self.nlp = spacy.load('en_core_web_sm')\n",
    "            self.nlp.max_length = 1500000\n",
    "        elif software == 'presidio':\n",
    "            self.analyzer = AnalyzerEngine()\n",
    "        else:\n",
    "            raise Exception(f'Software {software} is not supported')\n",
    "\n",
    "        \n",
    "    def _get_entities(self, document):\n",
    "        try:\n",
    "            doc_len = len(document)\n",
    "            if doc_len > self.MAX_DOC_SIZE_FOR_SPACY:\n",
    "                document = document[:self.MAX_DOC_SIZE_FOR_SPACY]\n",
    "            doc = self.nlp(document)\n",
    "            return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "        except ValueError as e :\n",
    "            print(f'Error in document. Error: {e}')\n",
    "            return []\n",
    "        \n",
    "        \n",
    "    def _predict_spacy_verdict(self, row) -> ContentAnalysisResult:\n",
    "        result = ContentAnalysisResult()\n",
    "        count_persons = 0\n",
    "        sensitive_words = find_sensitive_words(row['email_text'])\n",
    "        if len(sensitive_words) > 0:\n",
    "            for word in sensitive_words:\n",
    "                result.piis.append(word)\n",
    "        if row['quids'] and len(row['quids']) > 0: \n",
    "            result.quids = row['quids']\n",
    "        elif row['sensitive'] and len(row['sensitive']) > 0:\n",
    "            result.piis.append(row['sensitive'])\n",
    "        elif row['potentially_sensitive'] and len(row['potentially_sensitive']) > 0:\n",
    "            for ent in row['potentially_sensitive']:\n",
    "                if ent[1] == 'DATE':\n",
    "                    continue\n",
    "                elif ent[1] == 'TIME':\n",
    "                    continue\n",
    "                elif ent[1] == 'QUANTITY':\n",
    "                    continue\n",
    "                elif ent[1] == 'ORDINAL':\n",
    "                    continue\n",
    "                elif ent[1] == 'CARDINAL':\n",
    "                    phone_numbers = find_all_phone_numbers(ent[0])\n",
    "                    credit_cards = find_all_credit_cards(ent[0])\n",
    "                    ssns = find_all_ssn(ent[0])\n",
    "                    for phone_number in phone_numbers:\n",
    "                        result.piis.append(phone_number)\n",
    "                    for credit_card in credit_cards:\n",
    "                        result.piis.append(credit_card)\n",
    "                    for ssn in ssns:\n",
    "                        result.piis.append(ssn)\n",
    "                \n",
    "                #todo maor - think about this, do we want to enter 2 qids in that case? let's see\n",
    "                # elif ent[1] == 'PERSON':\n",
    "                #     count_persons += 1\n",
    "                #     if count_persons > 2:\n",
    "                #         return 'Sensitive'\n",
    "                #     continue\n",
    "        return result\n",
    "    \n",
    "    def analyze(self, row: pd.DataFrame) -> ContentAnalysisResult:\n",
    "        result: ContentAnalysisResult()\n",
    "        copied_row = row.copy()\n",
    "        \n",
    "        if self.software == 'spacy':\n",
    "            result = self._anaylze_spacy(copied_row)\n",
    "        elif self.software == 'presidio':\n",
    "            result = self._analyze_presidio(copied_row)\n",
    "        else:\n",
    "            raise Exception(f'Software {self.software} is not supported')\n",
    "        \n",
    "        print(f'{self.software} based content analysis result: {result}')\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _anaylze_spacy(self, row) -> ContentAnalysisResult:\n",
    "        row['entities'] = self._get_entities(row['email_text'])\n",
    "        unique_entities = set()\n",
    "        for entities in row['entities']:\n",
    "            for ent in entities:\n",
    "                if len(ent) < 2:\n",
    "                    print(f'Entity {ent} is not valid')\n",
    "                    continue\n",
    "                unique_entities.add(ent[1])\n",
    "        row['sensitive'] =  [(ent[0], ent[1]) for ent in row['entities'] if ent[1] in ContentAnalyzer.SENSITIVE]\n",
    "        row['quids'] = [(ent[0], ent[1]) for ent in row['entities'] if ent[1] in ContentAnalyzer.QUIDS]\n",
    "        row['potentially_sensitive'] = [(ent[0], ent[1]) for ent in row['entities'] if ent[1] in ContentAnalyzer.POTENTIALLY_SENSITIVE]\n",
    "        spacy_result = self._predict_spacy_verdict(row)\n",
    "        \n",
    "        return spacy_result\n",
    "    \n",
    "    NON_SENSITIVE = ['EMAIL_ADDRESS', 'URL', 'ORG']\n",
    "    SENSITIVE = ['IP_ADDRESS', 'AU_ACN', 'US_ITIN', 'UK_NHS', 'AU_TFN', 'US_BANK_NUMBER', 'IN_PAN', 'US_DRIVER_LICENSE', 'IN_VEHICLE_REGISTRATION', 'SG_NRIC_FIN', 'US_SSN', 'US_PASSPORT', 'MEDICAL_LICENSE', 'PHONE_NUMBER']\n",
    "    QUASI_SENSITIVE = ['NRP', 'LOCATION', 'PERSON', 'DATE_TIME', 'GPE']\n",
    "    \n",
    "    @staticmethod\n",
    "    def _predict_presidio_verdict(row) -> ContentAnalysisResult:\n",
    "        result = ContentAnalysisResult()\n",
    "        \n",
    "        persons_counter = 0\n",
    "        if row is None:\n",
    "            return result\n",
    "        \n",
    "        email_text = row['email_text']\n",
    "        if email_text is None:\n",
    "            return result\n",
    "        sensitive_words = find_sensitive_words(row['email_text'])\n",
    "        phone_numbers = find_all_phone_numbers(email_text)\n",
    "        credit_cards = find_all_credit_cards(email_text)\n",
    "        ssns = find_all_ssn(email_text)\n",
    "        \n",
    "        for word in sensitive_words:\n",
    "            result.piis.append(word)\n",
    "        for phone_number in phone_numbers:\n",
    "            result.piis.append(phone_number)\n",
    "        for credit_card in credit_cards:\n",
    "            result.piis.append(credit_card)\n",
    "        for ssn in ssns:\n",
    "            result.piis.append(ssn)\n",
    "            \n",
    "    \n",
    "        if row['pii'] is None:\n",
    "            return result\n",
    "        \n",
    "        for pii in row['pii']:\n",
    "            if pii.score < 0.5:\n",
    "                continue\n",
    "            if pii.entity_type.startswith('IN_'):\n",
    "                continue\n",
    "            if pii.entity_type in ContentAnalyzer.NON_SENSITIVE:\n",
    "                continue\n",
    "            if pii.entity_type in ContentAnalyzer.SENSITIVE:\n",
    "                result.piis.append(pii)\n",
    "            if pii.entity_type in ContentAnalyzer.QUASI_SENSITIVE: \n",
    "                # todo maor - think about person\n",
    "                # if pii.entity_type == 'PERSON':\n",
    "                #     persons_counter += 1\n",
    "                #     if persons_counter > 2:\n",
    "                #         return 'Sensitive'\n",
    "                # else:\n",
    "                result.quids.append(pii)\n",
    "    \n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def build_pii_text(self, email_body_text, result):\n",
    "        start = result.start\n",
    "        end = result.end\n",
    "        pii_text = email_body_text[start:end]\n",
    "        return pii_text\n",
    "        \n",
    "    \n",
    "    counter = 0\n",
    "    def analyze_pii(self, email_body_text):\n",
    "        global counter\n",
    "        counter+= 1\n",
    "        if counter % 200 == 0:\n",
    "            print(f'Processed {counter} documents')\n",
    "        pii_list = []\n",
    "        email_body_text = email_body_text[:2000]\n",
    "        \n",
    "        try:\n",
    "            results = self.analyzer.analyze(text=email_body_text, language='en')\n",
    "        except Exception as e:\n",
    "            print(f'Error in document. Error: {e}')\n",
    "            return []\n",
    "        \n",
    "        for result in results:\n",
    "            pii_text = self.build_pii_text(email_body_text, result)\n",
    "            pii = PII(result.entity_type, result.score, pii_text)\n",
    "            pii_list.append(pii)\n",
    "    \n",
    "        return pii_list\n",
    "    \n",
    "\n",
    "\n",
    "    def _analyze_presidio(self, row) -> ContentAnalysisResult:\n",
    "        row['pii'] = row['email_text'].apply(lambda x: self.analyze_pii(x))\n",
    "        presidio_result = self._predict_presidio_verdict(row)\n",
    "        \n",
    "        return presidio_result\n"
   ],
   "outputs": [],
   "execution_count": 623
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.219810Z",
     "start_time": "2024-05-11T15:01:17.217240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import preprocessing\n",
    "import pickle\n",
    "\n",
    "class TopicAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model = pickle.load(open(\"random_forest_model.pkl\", 'rb'))\n",
    "        self.vectorizer = pickle.load(open(\"tfidf_vectorizer.pkl\", 'rb'))\n",
    "        \n",
    "    def _transform(self,text):\n",
    "        return self.vectorizer.transform([text])\n",
    "        \n",
    "    def predict(self, row) -> TopicAnalysisResult:\n",
    "        result = TopicAnalysisResult()\n",
    "        result.is_legal = self.is_legal(row)\n",
    "        result.is_business = self.is_business(row)\n",
    "        result.is_finance = self.is_finance(row)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def is_business(self, row):        \n",
    "        text = self.process_text(row)\n",
    "        res =  self.model.predict(text)[0]\n",
    "        if res[2] != 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_finance(self, row):\n",
    "        text = self.process_text(row)\n",
    "        res =  self.model.predict(text)[0]\n",
    "        if res[1] != 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_legal(self, row):\n",
    "        text = self.process_text(row)\n",
    "        res = self.model.predict(text)[0]\n",
    "        if res[0] != 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def process_text(self, row):\n",
    "        subject = row['Subject']\n",
    "        body = row['email_body']\n",
    "        text = preprocessing.preprocess_text(subject + \" \" + body, should_remove_small_words=True, should_remove_digits=True, lemmatize=True)\n",
    "        text = self._transform(text)\n",
    "        return text\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": 624
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.453992Z",
     "start_time": "2024-05-11T15:01:17.222690Z"
    }
   },
   "source": [
    "def _only_1_rules_are_violated(static_rule_violations_by_rule_id):\n",
    "    rule_2_prefix = '2.'\n",
    "    \n",
    "    for rule_id in static_rule_violations_by_rule_id.keys():\n",
    "        if rule_2_prefix in rule_id and static_rule_violations_by_rule_id[rule_id]:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "\n",
    "def only_this_rule_violated(static_rule_violations_by_rule_id, rule_id):\n",
    "    return static_rule_violations_by_rule_id[rule_id] == True and sum(static_rule_violations_by_rule_id.values())\n",
    "\n",
    "\n",
    "def _pre_process(mail_row):\n",
    "    subject = mail_row['Subject']\n",
    "    body = mail_row['email_body']\n",
    "    text = preprocessing.preprocess_text(subject + \" \" + body, should_remove_small_words=True, should_remove_digits=False, lemmatize=True)\n",
    "    mail_row['email_text'] = text\n",
    "    return mail_row\n",
    "\n",
    "\n",
    "class Enforcer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.static_analyzer = StaticAnalyzer()\n",
    "        self.topic_analyzer = TopicAnalyzer()\n",
    "        self.content_analyzer = ContentAnalyzer()\n",
    "\n",
    "    def enforce(self, mail_row) -> EnforcerResult:\n",
    "        result = EnforcerResult()\n",
    "        copied_row = mail_row.copy()\n",
    "        processed_row = _pre_process(copied_row)\n",
    "        \n",
    "        static_rule_violations_by_rule_id: {str : bool} = self.analyze_static(processed_row)\n",
    "        content_analysis: ContentAnalysisResult\n",
    "        topic_analysis: TopicAnalysisResult\n",
    "    \n",
    "        # static analysis\n",
    "        if any(static_rule_violations_by_rule_id.values()) is False:\n",
    "            print(f'After static analysis, The Email is not violating any rule and therefore ALLOWED')\n",
    "            return result\n",
    "        \n",
    "        if only_this_rule_violated(static_rule_violations_by_rule_id, rule_id='2.3'):\n",
    "            print(f'Only rule 2.3 is potentially violated. therefore, we can skip topic analysis')\n",
    "            content_analysis: ContentAnalysisResult = self.content_analyzer.analyze(processed_row)\n",
    "            \n",
    "            if content_analysis.is_sensitive('2.3'):\n",
    "                print(f'Email is violating rule 2.3 due to content analysis: {content_analysis} and therefore BLOCKED')\n",
    "                result.violated_rules.append('2.3')\n",
    "            else:\n",
    "                print(f'Email is not violating any rule due to content analysis: {content_analysis} and therefore ALLOWED')\n",
    "            return result\n",
    "        \n",
    "        print(f'Will analyze topic for email, as all rules left required topic analysis')\n",
    "        topic_analysis = self.topic_analyzer.predict(processed_row)\n",
    "        \n",
    "        if _only_1_rules_are_violated(static_rule_violations_by_rule_id):\n",
    "            content_analysis: ContentAnalysisResult = self.content_analyzer.analyze(processed_row) # todo maor - delete\n",
    "            print(f'Only Policy 1# rules are violated statically, can skip content analysis')\n",
    "        else:\n",
    "            print(f'Will analyze content for , as all rules left required content analysis (2)')\n",
    "            content_analysis: ContentAnalysisResult = self.content_analyzer.analyze(processed_row)\n",
    "        \n",
    "        for rule_id, static_rule_violation in static_rule_violations_by_rule_id.items():\n",
    "            if static_rule_violation:\n",
    "                print(f'Email is violating rule {rule_id} due to static analysis. Checking content analysis and topic analysis if needed')\n",
    "            \n",
    "                is_violated_rule_by_content_analysis = self._is_violating_rule_by_content(rule_id, content_analysis)\n",
    "                is_violated_rule_by_topic_analysis = self._is_violating_rule_by_topic(rule_id, topic_analysis)\n",
    "            \n",
    "                if is_violated_rule_by_content_analysis and is_violated_rule_by_topic_analysis:\n",
    "                    print(f'Email is violating rule {rule_id} due to content analysis or topic analysis and therefore BLOCKED')\n",
    "                    result.violated_rules.append(rule_id)\n",
    "                else:\n",
    "                    print(f'Email is not violating rule {rule_id} due to content analysis or topic analysis and therefore ALLOWED')\n",
    "            else:\n",
    "                print(f'Email is not violating rule {rule_id} due to static analysis')\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def analyze_static(self, processed_row) -> {str : bool}:\n",
    "        static_rule_violations_by_rule_id: {str: bool} = {\n",
    "            '1.1': self.static_analyzer.is_violating_rule_1_1(processed_row),\n",
    "            '1.2': self.static_analyzer.is_violating_rule_1_2(processed_row),\n",
    "            '1.3': self.static_analyzer.is_violating_rule_1_3(processed_row),\n",
    "            '2.1': self.static_analyzer.is_violating_rule_2_1(processed_row),\n",
    "            '2.2': self.static_analyzer.is_violating_rule_2_2(processed_row),\n",
    "            '2.3': self.static_analyzer.is_violating_rule_2_3(processed_row)\n",
    "        }\n",
    "        \n",
    "        return static_rule_violations_by_rule_id\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_violating_rule_by_content(rule_id, content_analysis: ContentAnalysisResult):\n",
    "        if '1.' in rule_id:\n",
    "            return False\n",
    "        if rule_id == '2.1' or rule_id == '2.2':\n",
    "            return content_analysis.is_sensitive\n",
    "        elif rule_id == '2.3':\n",
    "            return content_analysis.is_sensitive(rule_id)\n",
    "        else:\n",
    "            raise Exception(f'Rule {rule_id} is not supported')\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _is_violating_rule_by_topic(rule_id, topic_analysis: TopicAnalysisResult):\n",
    "        if rule_id == '1.1':\n",
    "            return topic_analysis.is_legal\n",
    "        elif rule_id == '1.2':\n",
    "            return topic_analysis.is_finance\n",
    "        elif rule_id == '1.3':\n",
    "            return topic_analysis.is_finance or topic_analysis.is_business\n",
    "        elif rule_id == '2.1':\n",
    "            return topic_analysis.is_finance\n",
    "        elif rule_id == '2.2':\n",
    "            return topic_analysis.is_business\n",
    "        elif rule_id == '2.3':\n",
    "            return False\n",
    "        else: \n",
    "            raise Exception(f'Rule {rule_id} is not supported for topic analysis')\n",
    "        \n",
    "enforcer = Enforcer()\n",
    "\n",
    "def classify_mail_extended(mail_row) -> EnforcerResult:\n",
    "    enforcer_results = enforcer.enforce(mail_row)\n",
    "    return enforcer_results\n",
    "\n",
    "def classify_mail(mail_row) -> bool:\n",
    "    enforcer_results = enforcer.enforce(mail_row)\n",
    "    is_allowed = enforcer_results.is_allowed()\n",
    "    verdict_prediction = 'ALLOWED' if is_allowed else 'BLOCKED'\n",
    "    print(f'Email Enforcer results: {enforcer_results}. Will be {verdict_prediction}')\n",
    "    return is_allowed\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 625
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:19.850951Z",
     "start_time": "2024-05-11T15:01:17.454587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = enron_df.sample(100,random_state=7).copy()\n",
    "test_df['is_allowed'] = test_df.apply(lambda row: classify_mail_extended(row), axis=1)\n",
    "test_df.head(100)\n",
    "\n",
    "# todo maor - Print accuracies"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Lloyd Subject', 'ORG'), ('Enron', 'ORG'), ('Lloyd May', 'ORG'), ('JMF File', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('America', 'GPE'), ('Loftus', 'ORG'), ('Diamond', 'GPE'), ('Calcagno', 'GPE'), (\"Chris Subject America's\", 'ORG')] | PII: [])\n",
      "Only Policy 1# rules are violated statically, can skip content analysis\n",
      "Email is violating rule 1.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('VAR', 'ORG'), ('RisktRAC VAR', 'ORG'), ('Middle Office', 'ORG'), ('RAC', 'ORG'), ('RAC', 'ORG'), ('Follow', 'ORG'), ('Oslo Action Mike', 'ORG'), ('DPR daily basis', 'ORG'), ('GCP Action', 'ORG'), ('EOL', 'ORG'), ('STP', 'ORG')] | PII: ['attach'])\n",
      "Only Policy 1# rules are violated statically, can skip content analysis\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is violating rule 1.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.2 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Texas', 'GPE'), ('Enron', 'ORG'), ('Texas', 'GPE'), ('The NewPower Company', 'ORG'), ('NewPower', 'ORG'), ('Enron', 'ORG'), ('America', 'GPE'), ('Texas', 'GPE'), ('Houston', 'GPE'), ('NewPower', 'ORG'), ('First Participate Enrollment NewPower', 'ORG'), ('NewPower', 'ORG'), ('Enron', 'ORG'), ('NewPower', 'ORG'), ('NewPower', 'ORG'), ('Enron', 'ORG'), ('NewPower', 'ORG'), ('NewPower', 'ORG'), ('NewPower', 'ORG')] | PII: [])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Texas', 'GPE'), ('Enron', 'ORG'), ('Texas', 'GPE'), ('The NewPower Company', 'ORG'), ('NewPower', 'ORG'), ('Enron', 'ORG'), ('America', 'GPE'), ('Texas', 'GPE'), ('Houston', 'GPE'), ('NewPower', 'ORG'), ('First Participate Enrollment NewPower', 'ORG'), ('NewPower', 'ORG'), ('Enron', 'ORG'), ('NewPower', 'ORG'), ('NewPower', 'ORG'), ('Enron', 'ORG'), ('NewPower', 'ORG'), ('NewPower', 'ORG'), ('NewPower', 'ORG')] | PII: []) and therefore BLOCKED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Kvaerner Process Legal Department', 'ORG')] | PII: ['attach', 'confidential', 'attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Kvaerner Process Legal Department', 'ORG')] | PII: ['attach', 'confidential', 'attach']) and therefore BLOCKED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "Entity # is not valid\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is not violating any rule due to content analysis: (Sensitive: False | Quids: [] | PII: []) and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "Entity 3 is not valid\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [] | PII: ['confidential'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [] | PII: ['confidential']) and therefore BLOCKED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('CFMA', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Chris Long/Corp/Enron', 'ORG'), ('Fifth Avenue Rockefeller Center', 'FAC'), ('New York', 'GPE')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('FYI', 'ORG'), ('EES', 'ORG'), ('ENA', 'ORG'), ('ASAP', 'FAC'), ('East Bay Drive', 'LOC'), ('Olympia', 'GPE'), ('Washington', 'GPE'), ('fed', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('R98035B', 'ORG'), ('Future Technology Task Force', 'ORG'), ('Executive Committee', 'ORG'), ('EC', 'ORG'), ('Boeing Seattle', 'ORG'), ('Washington', 'GPE'), ('GISB Office', 'ORG'), ('PDF', 'ORG')] | PII: ['attach', 'attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('R98035B', 'ORG'), ('Future Technology Task Force', 'ORG'), ('Executive Committee', 'ORG'), ('EC', 'ORG'), ('Boeing Seattle', 'ORG'), ('Washington', 'GPE'), ('GISB Office', 'ORG'), ('PDF', 'ORG')] | PII: ['attach', 'attach']) and therefore BLOCKED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('SMTP', 'ORG'), ('SMTP', 'ORG'), ('Enron', 'ORG'), ('Enron', 'ORG'), ('North Birmingham', 'GPE'), ('Alabama', 'GPE')] | PII: ['attach', 'attach', 'confidential'])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Lisa.Bills@enron.com', 'ORG'), ('Roseann.Engeldorf@enron.com', 'ORG'), ('Scott.Dieball@enron.com', 'ORG'), ('Stephen.swift@ps.ge.com', 'ORG'), ('Michael.barnas@ps.ge.com', 'ORG'), ('Kent.shoemaker@ae.ge.com', 'ORG'), ('kay.mann@enron.com', 'ORG'), ('Subject WEEKLY CONFERENCE CALL Importance High', 'ORG'), ('CST', 'ORG'), ('Dial', 'ORG'), ('Houston', 'GPE')] | PII: ['confidential', 'attach', 'confidential'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Lisa.Bills@enron.com', 'ORG'), ('Roseann.Engeldorf@enron.com', 'ORG'), ('Scott.Dieball@enron.com', 'ORG'), ('Stephen.swift@ps.ge.com', 'ORG'), ('Michael.barnas@ps.ge.com', 'ORG'), ('Kent.shoemaker@ae.ge.com', 'ORG'), ('kay.mann@enron.com', 'ORG'), ('Subject WEEKLY CONFERENCE CALL Importance High', 'ORG'), ('CST', 'ORG'), ('Dial', 'ORG'), ('Houston', 'GPE')] | PII: ['confidential', 'attach', 'confidential']) and therefore BLOCKED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('NOV', 'ORG')] | PII: [])\n",
      "Email is not violating any rule due to content analysis: (Sensitive: True | Quids: [('NOV', 'ORG')] | PII: []) and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Direct Report', 'ORG'), ('Peer/Colleague', 'ORG'), ('Dennis Ward FSD Data Services', 'ORG'), ('Debbie Nowak Enron', 'FAC'), ('Goldsmith Company', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Bryson', 'ORG'), ('Page', 'GPE'), ('Shields', 'GPE'), ('west coast', 'LOC'), ('Participant Code', 'ORG'), ('Mt. Adams', 'LOC'), ('Bryson', 'ORG'), ('Page', 'GPE'), ('Shields', 'GPE'), ('Bryson', 'ORG'), ('Page', 'GPE'), ('Shields', 'GPE')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Allegretti', 'ORG'), ('Daniel', 'GPE'), ('Allen', 'GPE'), ('Barnes', 'GPE'), ('Bellas', 'GPE'), ('Kirsten', 'GPE'), ('Bestard', 'ORG'), ('Binns', 'GPE'), ('Darran', 'GPE'), ('Scott', 'ORG'), ('Boston', 'GPE'), ('Burns', 'GPE'), ('Stephen', 'GPE'), ('Canovas', 'GPE'), ('Comnes', 'GPE'), ('Connor', 'GPE'), ('Cooney', 'ORG'), ('Decker', 'GPE'), ('Dernehl', 'ORG'), ('Ginger', 'ORG'), ('Fromer', 'ORG'), ('Fulton', 'ORG'), ('Guerrero', 'ORG'), ('Janel', 'ORG'), ('Hartfield', 'GPE'), ('Hetrick', 'GPE'), ('Hoatson', 'ORG'), ('Huson, Maggy', 'ORG'), ('Ibrahim', 'GPE'), ('Kishigami', 'GPE'), ('Kikumi', 'GPE'), ('Knight, Laurie', 'ORG'), ('Leibman', 'ORG'), ('Leonardo', 'GPE'), ('Alberto', 'GPE'), ('Linnell', 'GPE'), ('Long', 'GPE'), ('Mara', 'GPE'), ('Maurer', 'GPE'), ('McVicker, Maureen; Migden', 'ORG'), ('Moore', 'ORG'), ('Carin', 'GPE'), ('Neustaedter= Robert', 'GPE'), ('Noske', 'GPE'), ('Novosel', 'ORG'), ('Ogenyi', 'ORG'), ('Palmer', 'GPE'), ('Petrochko', 'ORG'), ('Pharms', 'ORG'), ('Melinda', 'ORG'), ('Reyna', 'GPE'), ('Margo', 'ORG'), ('Helen', 'GPE'), ('Roan', 'GPE'), ('Rodriquez', 'ORG'), ('Ryall', 'GPE'), ('Shapiro', 'ORG'), ('Shelk', 'ORG'), ('Staines', 'GPE'), ('Stubbings', 'GPE'), ('Randy', 'ORG'), ('Fino', 'ORG'), ('Warner', 'ORG'), ('Geriann', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "Entity 1 is not valid\n",
      "Entity 2 is not valid\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('First Gas Privileged Confidential', 'ORG'), ('Janice Moore', 'ORG'), ('Siemens', 'ORG'), ('Siemens', 'ORG'), (\"First Gas'\", 'ORG'), ('First Gas', 'ORG'), ('Siemens', 'ORG'), ('Siemens First Gas', 'ORG'), ('First Gas', 'ORG'), ('First Gas', 'ORG'), ('First Gas', 'ORG')] | PII: ['confidential'])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Jordan', 'GPE')] | PII: [])\n",
      "Email is not violating any rule due to content analysis: (Sensitive: True | Quids: [('Jordan', 'GPE')] | PII: []) and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Canadian Financial Trading Confirmation Process Further', 'ORG'), ('Canada', 'GPE'), ('Enron Canada', 'ORG'), ('Calgary', 'GPE'), ('Calgary', 'GPE'), ('McKay', 'GPE'), ('Milnthorp Zufferli', 'ORG'), ('Enron Canada', 'ORG'), ('Houston', 'GPE'), ('Calgary', 'GPE')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('NCAA', 'ORG'), ('NCAA', 'ORG'), ('Houston', 'GPE'), ('Reuters', 'ORG'), ('Sports.com', 'ORG'), ('CBS', 'ORG'), ('EnronOnline', 'ORG'), ('Reters', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Spectron/Enron Celebrity', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Jeff Subject Crisis', 'ORG'), ('Enron', 'ORG'), ('Tokyo', 'GPE'), ('Enron', 'ORG'), ('Japan', 'GPE'), ('Japan', 'GPE'), ('Harvard', 'ORG'), ('Norway', 'GPE'), ('Australia', 'GPE'), ('Enron Metal', 'ORG'), ('Enron', 'ORG'), ('Enron', 'ORG'), ('Enron', 'ORG'), ('Japan', 'GPE'), ('GE', 'ORG'), ('Asia', 'LOC'), ('Enron', 'ORG'), ('Enron', 'ORG'), ('MSN Hotmail', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Michigan', 'GPE'), ('Africa', 'LOC'), ('Africa', 'LOC'), ('Spirit', 'ORG')] | PII: [])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Michigan', 'GPE'), ('Africa', 'LOC'), ('Africa', 'LOC'), ('Spirit', 'ORG')] | PII: []) and therefore BLOCKED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG')] | PII: ['confidential', 'attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG'), ('Matthew.Lenhart@enron.com', 'ORG')] | PII: ['confidential', 'attach']) and therefore BLOCKED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Anne Kelly Duke Energy', 'ORG'), ('Soto', 'ORG'), ('Soto', 'ORG')] | PII: [])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Anne Kelly Duke Energy', 'ORG'), ('Soto', 'ORG'), ('Soto', 'ORG')] | PII: []) and therefore BLOCKED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('CAISO Energy Dynegy Direct', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('EXCEPT', 'ORG'), ('Sitara', 'GPE'), ('Click Edit', 'ORG'), ('Click Facility', 'ORG'), ('SeaRobin Offshore', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Enron', 'ORG'), ('Mitsubishi Corporation', 'ORG'), (\"Mitsubishi ECT's\", 'ORG'), ('Mitsubishi', 'ORG'), ('U.K.', 'GPE'), ('ECT', 'ORG'), ('Thailand', 'GPE')] | PII: [])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Enron', 'ORG'), ('Mitsubishi Corporation', 'ORG'), (\"Mitsubishi ECT's\", 'ORG'), ('Mitsubishi', 'ORG'), ('U.K.', 'GPE'), ('ECT', 'ORG'), ('Thailand', 'GPE')] | PII: []) and therefore BLOCKED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Ogenyi', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [] | PII: ['attach'])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is violating rule 1.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.2 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is not violating any rule due to content analysis: (Sensitive: False | Quids: [] | PII: []) and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is not violating any rule due to content analysis: (Sensitive: False | Quids: [] | PII: []) and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [] | PII: ['attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [] | PII: ['attach']) and therefore BLOCKED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('stinson beach', 'GPE')] | PII: [])\n",
      "Email is not violating any rule due to content analysis: (Sensitive: True | Quids: [('stinson beach', 'GPE')] | PII: []) and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('FYI Options', 'ORG'), ('Murrell', 'ORG'), ('FERC', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('California', 'GPE'), ('SCE', 'ORG'), ('CTC', 'ORG'), ('Cooley', 'GPE'), ('Smith', 'GPE'), ('Shapiro', 'ORG'), ('Mara', 'GPE'), ('Sharp', 'ORG'), ('Noske', 'GPE'), ('Dernehl', 'ORG'), ('Ginger', 'ORG'), ('Rivas', 'GPE'), ('Mariaelena', 'GPE'), ('Alamo', 'FAC'), ('California', 'GPE')] | PII: [])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('California', 'GPE'), ('SCE', 'ORG'), ('CTC', 'ORG'), ('Cooley', 'GPE'), ('Smith', 'GPE'), ('Shapiro', 'ORG'), ('Mara', 'GPE'), ('Sharp', 'ORG'), ('Noske', 'GPE'), ('Dernehl', 'ORG'), ('Ginger', 'ORG'), ('Rivas', 'GPE'), ('Mariaelena', 'GPE'), ('Alamo', 'FAC'), ('California', 'GPE')] | PII: []) and therefore BLOCKED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Middle East', 'LOC'), ('Enron', 'ORG'), ('Enron', 'ORG')] | PII: ['attach', 'attach', 'attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Middle East', 'LOC'), ('Enron', 'ORG'), ('Enron', 'ORG')] | PII: ['attach', 'attach', 'attach']) and therefore BLOCKED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Enron', 'ORG')] | PII: [])\n",
      "Email is violating rule 1.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Assignment Agreement', 'ORG'), ('Negative CTC Receivable', 'ORG'), ('L.L.P.', 'ORG')] | PII: ['attach', 'confidential', 'attach', 'attach', 'attach'])\n",
      "Email is violating rule 1.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is not violating any rule due to content analysis: (Sensitive: False | Quids: [] | PII: []) and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Only Policy 1# rules are violated statically, can skip content analysis\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is violating rule 1.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.2 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Board Meeting Materials', 'ORG'), ('ERCOT Board', 'ORG'), ('BOD Responsibilities.doc Fee Increase', 'ORG'), ('PUCT', 'ORG')] | PII: ['attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Board Meeting Materials', 'ORG'), ('ERCOT Board', 'ORG'), ('BOD Responsibilities.doc Fee Increase', 'ORG'), ('PUCT', 'ORG')] | PII: ['attach']) and therefore BLOCKED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Veronica Espinoza/Corp/Enron@ENRON', 'ORG'), ('National Energy Trade', 'ORG'), ('LLC', 'ORG'), ('Credit', 'ORG'), ('Letter Credit', 'ORG'), ('Credit', 'ORG'), ('Credit Watch List', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Enron', 'ORG'), ('EVP Chief Staff', 'ORG')] | PII: [])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('Enron', 'ORG'), ('EVP Chief Staff', 'ORG')] | PII: []) and therefore BLOCKED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Houston', 'GPE'), ('CDT', 'ORG'), ('Paul Simons/LON/ECT@ECT Subject Bond', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is violating rule 1.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.2 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [] | PII: ['attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [] | PII: ['attach']) and therefore BLOCKED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Keohane', 'GPE'), ('Tana Subject America', 'ORG'), ('US', 'GPE'), ('New York', 'GPE'), (\"New York's\", 'GPE'), ('Peter Subject America', 'ORG'), ('Tana Subject America', 'ORG'), ('SNOUFERSCH@aol.com', 'ORG'), ('Zakai@aol.com', 'ORG'), ('Toronto', 'GPE')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('AGA', 'ORG'), ('AGA', 'ORG'), ('Volumes Consuming Region East', 'ORG'), ('Consuming Region East', 'LOC')] | PII: [])\n",
      "Email is violating rule 1.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('iraq', 'GPE'), ('Brendan Fitzsimmons/NA/Enron@Enron', 'ORG'), ('iraq', 'GPE'), ('israel', 'GPE'), ('Israel', 'GPE'), ('Iraq', 'GPE')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('EOL Credit Responses', 'ORG'), ('Peabody COALTRADE, Inc.', 'ORG'), ('United States Gypsum Company', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('FERC', 'ORG')] | PII: ['attach'])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('FERC', 'ORG')] | PII: ['attach']) and therefore BLOCKED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is violating rule 1.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Dominion Transmission', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 2.2 due to static analysis\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('ANZ Bank', 'ORG'), ('Sara Shackleton', 'ORG'), ('Smith Street', 'ORG'), ('Houston', 'GPE'), ('Texas', 'GPE'), ('ECT@ECT Subject ANZ Bank', 'ORG'), ('ISDA', 'ORG'), ('ANZ Bank', 'ORG')] | PII: ['attach'])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is violating rule 1.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 1.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Enron', 'ORG')] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Only rule 2.3 is potentially violated. therefore, we can skip topic analysis\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('FREE', 'ORG'), ('MSN', 'ORG')] | PII: [])\n",
      "Email is violating rule 2.3 due to content analysis: (Sensitive: True | Quids: [('FREE', 'ORG'), ('MSN', 'ORG')] | PII: []) and therefore BLOCKED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('City Azusa Bonnevile Power Administration', 'ORG'), ('Stephanie Panus Enron Wholesale Services', 'ORG')] | PII: ['attach'])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "Entity 1 is not valid\n",
      "Entity 2 is not valid\n",
      "spacy based content analysis result: (Sensitive: True | Quids: [('Draft Business Plan Enron Net Works South America', 'ORG'), ('FYI', 'ORG'), ('South America', 'LOC'), ('Business Unit', 'ORG'), ('Networks', 'ORG'), ('Houston', 'GPE'), ('Enron SA', 'ORG'), ('Business Units Once', 'ORG'), ('Enron', 'ORG'), ('SA/Enron@Enron', 'ORG'), (\"D'Arcy Carroll/SA/Enron@Enron Subject Draft Business Plan\", 'ORG'), ('Business Plan South America', 'ORG'), (\"D'Arcy\", 'ORG')] | PII: ['attach'])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "After static analysis, The Email is not violating any rule and therefore ALLOWED\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is not violating rule 2.1 due to static analysis\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n",
      "Will analyze topic for email, as all rules left required topic analysis\n",
      "Will analyze content for , as all rules left required content analysis (2)\n",
      "spacy based content analysis result: (Sensitive: False | Quids: [] | PII: [])\n",
      "Email is not violating rule 1.1 due to static analysis\n",
      "Email is not violating rule 1.2 due to static analysis\n",
      "Email is not violating rule 1.3 due to static analysis\n",
      "Email is violating rule 2.1 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is not violating rule 2.1 due to content analysis or topic analysis and therefore ALLOWED\n",
      "Email is violating rule 2.2 due to static analysis. Checking content analysis and topic analysis if needed\n",
      "Email is violating rule 2.2 due to content analysis or topic analysis and therefore BLOCKED\n",
      "Email is not violating rule 2.3 due to static analysis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                         Date                       From  \\\n",
       "467237  Fri, 23 Mar 2001 05:22:00 -0800 (PST)   evelyn.metoyer@enron.com   \n",
       "463489   Wed, 7 Feb 2001 11:23:00 -0800 (PST)     ken.skilling@enron.com   \n",
       "114389  Thu, 21 Jun 2001 10:24:09 -0700 (PDT)        m..forney@enron.com   \n",
       "229149   Thu, 6 Apr 2000 08:30:00 -0700 (PDT)       ruth.brown@enron.com   \n",
       "367540  Mon, 29 Oct 2001 12:59:08 -0800 (PST)    john.griffith@enron.com   \n",
       "...                                       ...                        ...   \n",
       "326778   Wed, 2 Aug 2000 01:31:00 -0700 (PDT)   mike.mcconnell@enron.com   \n",
       "106386  Tue, 14 Nov 2000 00:54:00 -0800 (PST)     mary.poorman@enron.com   \n",
       "472743  Thu, 17 Feb 2000 06:14:00 -0800 (PST)  debbie.brackett@enron.com   \n",
       "278327   Wed, 6 Sep 2000 10:09:00 -0700 (PDT)  matthew.lenhart@enron.com   \n",
       "26104   Thu, 24 Aug 2000 09:05:00 -0700 (PDT)  jeffrey.gossett@enron.com   \n",
       "\n",
       "                                                                                                         To  \\\n",
       "467237                                                                                 kate.symes@enron.com   \n",
       "463489                                                                              all.worldwide@enron.com   \n",
       "114389                                                                                    tom.may@enron.com   \n",
       "229149                                                                                  v&v.force@enron.com   \n",
       "367540                                                                              dutch.quigley@enron.com   \n",
       "...                                                                                                     ...   \n",
       "326778  jay.fitzgerald@enron.com, jeffrey.mcmahon@enron.com, allan.sommer@enron.com, \\n\\tlouise.kitchen@...   \n",
       "106386                                                      clem.cernosek@enron.com, daren.farmer@enron.com   \n",
       "472743                                                                              david.forster@enron.com   \n",
       "278327                                                                                chad.landry@enron.com   \n",
       "26104                              michael.moscoso@enron.com, steve.jackson@enron.com, sally.beck@enron.com   \n",
       "\n",
       "                                                                 X-To  \\\n",
       "467237                                                     Kate Symes   \n",
       "463489                                            All Enron Worldwide   \n",
       "114389                May, Tom </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tmay>   \n",
       "229149                                                 V&V Task Force   \n",
       "367540       Quigley, Dutch </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dquigle>   \n",
       "...                                                               ...   \n",
       "326778  Jay Fitzgerald, Jeffrey McMahon, Allan Sommer, Louise Kitchen   \n",
       "106386                                  Clem Cernosek, Daren J Farmer   \n",
       "472743                                                  David Forster   \n",
       "278327                                                    Chad Landry   \n",
       "26104                    Michael E Moscoso, Steve Jackson, Sally Beck   \n",
       "\n",
       "                                                           X-From  \\\n",
       "467237                                             Evelyn Metoyer   \n",
       "463489                                  Ken Lay and Jeff Skilling   \n",
       "114389  Forney, John M. </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JFORNEY>   \n",
       "229149                                             Ruth Ann Brown   \n",
       "367540  Griffith, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JGRIFFIT>   \n",
       "...                                                           ...   \n",
       "326778                                             Mike McConnell   \n",
       "106386                                               Mary Poorman   \n",
       "472743                                          Debbie R Brackett   \n",
       "278327                                            Matthew Lenhart   \n",
       "26104                                           Jeffrey C Gossett   \n",
       "\n",
       "                                                                                           X-cc  \\\n",
       "467237                                                                                            \n",
       "463489                                                                                            \n",
       "114389                                                                                            \n",
       "229149                                                                           V&V Assistants   \n",
       "367540                                                                                            \n",
       "...                                                                                         ...   \n",
       "326778                                                                          Philippe A Bibi   \n",
       "106386                                       Sherlyn Schumack, Katherine Herrera, Lauri A Allen   \n",
       "472743  Edmund Cooper, Justin Boyd, Mark Taylor, Dale Neuner, Mark Dilworth, William S Bradford   \n",
       "278327                                                                                            \n",
       "26104                                                                                             \n",
       "\n",
       "       X-bcc                                                Subject  \\\n",
       "467237                                                3-23 Checkout   \n",
       "463489                                       Organizational Changes   \n",
       "114389                                       RE: PERSONAL BEST NOMS   \n",
       "229149                              ETC Survey - Update & Questions   \n",
       "367540                                     FW: America's new weapon   \n",
       "...      ...                                                    ...   \n",
       "326778        Re: Draft Business Plan Enron Net Works South America   \n",
       "106386                                               Indian Springs   \n",
       "472743                                         Re: Collateral GTC's   \n",
       "278327                       Re: FW: ONE WEEK till Pajama Pub Crawl   \n",
       "26104                                                    Schedule C   \n",
       "\n",
       "                                                                                                 email_body  \\\n",
       "467237  BLOOMBERG\\n\\nTom Alonso\\nI am missing the following deals:\\n\\n1) Enron sells to Tractebal 25mw P...   \n",
       "463489  Enron is forming a new organization - - the Enron Xcelerator - - to drive the \\nformation and de...   \n",
       "114389  good thought,  I sent a separate e-mail to Tim Belden,  Greg Wolfe and Geir's supervisor Bill Wi...   \n",
       "229149                                                           Please see attached from Beth Tilney.\\n\\n    \n",
       "367540  dutch,\\n\\nplay this over the box\\n\\n -----Original Message-----\\nFrom: \\tMoon, Eric  \\nSent:\\tMo...   \n",
       "...                                                                                                     ...   \n",
       "326778  All,\\n\\nFYI, here is the latest draft of their business plan for your review and \\ncommentary.  ...   \n",
       "106386  I need HPL Sales and Purchases, back dated to 8/99 between HPL and TECO to \\nbook any processing...   \n",
       "472743   Perhaps it stems from our offline GTC's which give us some collateral rights \\nin any sale tran...   \n",
       "278327                                                                               i am going to tonight.   \n",
       "26104   ---------------------- Forwarded by Jeffrey C Gossett/HOU/ECT on 08/24/2000 \\n04:04 PM ---------...   \n",
       "\n",
       "       verdict violated_rules  is_between_ect_and_ees  is_EU_To_NA  is_c_suit  \\\n",
       "467237   ALLOW             []                   False        False      False   \n",
       "463489   ALLOW             []                   False        False      False   \n",
       "114389   ALLOW             []                   False        False       True   \n",
       "229149   ALLOW             []                   False        False      False   \n",
       "367540   ALLOW             []                    True        False      False   \n",
       "...        ...            ...                     ...          ...        ...   \n",
       "326778   ALLOW             []                   False        False       True   \n",
       "106386   ALLOW             []                   False        False      False   \n",
       "472743   ALLOW             []                   False        False      False   \n",
       "278327   ALLOW             []                   False        False       True   \n",
       "26104    ALLOW             []                   False        False       True   \n",
       "\n",
       "                     is_allowed  \n",
       "467237       Violated Rules: []  \n",
       "463489       Violated Rules: []  \n",
       "114389  Violated Rules: ['2.2']  \n",
       "229149       Violated Rules: []  \n",
       "367540       Violated Rules: []  \n",
       "...                         ...  \n",
       "326778  Violated Rules: ['2.2']  \n",
       "106386       Violated Rules: []  \n",
       "472743       Violated Rules: []  \n",
       "278327  Violated Rules: ['2.2']  \n",
       "26104   Violated Rules: ['2.2']  \n",
       "\n",
       "[100 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>Subject</th>\n",
       "      <th>email_body</th>\n",
       "      <th>verdict</th>\n",
       "      <th>violated_rules</th>\n",
       "      <th>is_between_ect_and_ees</th>\n",
       "      <th>is_EU_To_NA</th>\n",
       "      <th>is_c_suit</th>\n",
       "      <th>is_allowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467237</th>\n",
       "      <td>Fri, 23 Mar 2001 05:22:00 -0800 (PST)</td>\n",
       "      <td>evelyn.metoyer@enron.com</td>\n",
       "      <td>kate.symes@enron.com</td>\n",
       "      <td>Kate Symes</td>\n",
       "      <td>Evelyn Metoyer</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3-23 Checkout</td>\n",
       "      <td>BLOOMBERG\\n\\nTom Alonso\\nI am missing the following deals:\\n\\n1) Enron sells to Tractebal 25mw P...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Violated Rules: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463489</th>\n",
       "      <td>Wed, 7 Feb 2001 11:23:00 -0800 (PST)</td>\n",
       "      <td>ken.skilling@enron.com</td>\n",
       "      <td>all.worldwide@enron.com</td>\n",
       "      <td>All Enron Worldwide</td>\n",
       "      <td>Ken Lay and Jeff Skilling</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Organizational Changes</td>\n",
       "      <td>Enron is forming a new organization - - the Enron Xcelerator - - to drive the \\nformation and de...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Violated Rules: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114389</th>\n",
       "      <td>Thu, 21 Jun 2001 10:24:09 -0700 (PDT)</td>\n",
       "      <td>m..forney@enron.com</td>\n",
       "      <td>tom.may@enron.com</td>\n",
       "      <td>May, Tom &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tmay&gt;</td>\n",
       "      <td>Forney, John M. &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=JFORNEY&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RE: PERSONAL BEST NOMS</td>\n",
       "      <td>good thought,  I sent a separate e-mail to Tim Belden,  Greg Wolfe and Geir's supervisor Bill Wi...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Violated Rules: ['2.2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229149</th>\n",
       "      <td>Thu, 6 Apr 2000 08:30:00 -0700 (PDT)</td>\n",
       "      <td>ruth.brown@enron.com</td>\n",
       "      <td>v&amp;v.force@enron.com</td>\n",
       "      <td>V&amp;V Task Force</td>\n",
       "      <td>Ruth Ann Brown</td>\n",
       "      <td>V&amp;V Assistants</td>\n",
       "      <td></td>\n",
       "      <td>ETC Survey - Update &amp; Questions</td>\n",
       "      <td>Please see attached from Beth Tilney.\\n\\n</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Violated Rules: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367540</th>\n",
       "      <td>Mon, 29 Oct 2001 12:59:08 -0800 (PST)</td>\n",
       "      <td>john.griffith@enron.com</td>\n",
       "      <td>dutch.quigley@enron.com</td>\n",
       "      <td>Quigley, Dutch &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dquigle&gt;</td>\n",
       "      <td>Griffith, John &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=JGRIFFIT&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FW: America's new weapon</td>\n",
       "      <td>dutch,\\n\\nplay this over the box\\n\\n -----Original Message-----\\nFrom: \\tMoon, Eric  \\nSent:\\tMo...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Violated Rules: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326778</th>\n",
       "      <td>Wed, 2 Aug 2000 01:31:00 -0700 (PDT)</td>\n",
       "      <td>mike.mcconnell@enron.com</td>\n",
       "      <td>jay.fitzgerald@enron.com, jeffrey.mcmahon@enron.com, allan.sommer@enron.com, \\n\\tlouise.kitchen@...</td>\n",
       "      <td>Jay Fitzgerald, Jeffrey McMahon, Allan Sommer, Louise Kitchen</td>\n",
       "      <td>Mike McConnell</td>\n",
       "      <td>Philippe A Bibi</td>\n",
       "      <td></td>\n",
       "      <td>Re: Draft Business Plan Enron Net Works South America</td>\n",
       "      <td>All,\\n\\nFYI, here is the latest draft of their business plan for your review and \\ncommentary.  ...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Violated Rules: ['2.2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106386</th>\n",
       "      <td>Tue, 14 Nov 2000 00:54:00 -0800 (PST)</td>\n",
       "      <td>mary.poorman@enron.com</td>\n",
       "      <td>clem.cernosek@enron.com, daren.farmer@enron.com</td>\n",
       "      <td>Clem Cernosek, Daren J Farmer</td>\n",
       "      <td>Mary Poorman</td>\n",
       "      <td>Sherlyn Schumack, Katherine Herrera, Lauri A Allen</td>\n",
       "      <td></td>\n",
       "      <td>Indian Springs</td>\n",
       "      <td>I need HPL Sales and Purchases, back dated to 8/99 between HPL and TECO to \\nbook any processing...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Violated Rules: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472743</th>\n",
       "      <td>Thu, 17 Feb 2000 06:14:00 -0800 (PST)</td>\n",
       "      <td>debbie.brackett@enron.com</td>\n",
       "      <td>david.forster@enron.com</td>\n",
       "      <td>David Forster</td>\n",
       "      <td>Debbie R Brackett</td>\n",
       "      <td>Edmund Cooper, Justin Boyd, Mark Taylor, Dale Neuner, Mark Dilworth, William S Bradford</td>\n",
       "      <td></td>\n",
       "      <td>Re: Collateral GTC's</td>\n",
       "      <td>Perhaps it stems from our offline GTC's which give us some collateral rights \\nin any sale tran...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Violated Rules: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278327</th>\n",
       "      <td>Wed, 6 Sep 2000 10:09:00 -0700 (PDT)</td>\n",
       "      <td>matthew.lenhart@enron.com</td>\n",
       "      <td>chad.landry@enron.com</td>\n",
       "      <td>Chad Landry</td>\n",
       "      <td>Matthew Lenhart</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Re: FW: ONE WEEK till Pajama Pub Crawl</td>\n",
       "      <td>i am going to tonight.</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Violated Rules: ['2.2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26104</th>\n",
       "      <td>Thu, 24 Aug 2000 09:05:00 -0700 (PDT)</td>\n",
       "      <td>jeffrey.gossett@enron.com</td>\n",
       "      <td>michael.moscoso@enron.com, steve.jackson@enron.com, sally.beck@enron.com</td>\n",
       "      <td>Michael E Moscoso, Steve Jackson, Sally Beck</td>\n",
       "      <td>Jeffrey C Gossett</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Schedule C</td>\n",
       "      <td>---------------------- Forwarded by Jeffrey C Gossett/HOU/ECT on 08/24/2000 \\n04:04 PM ---------...</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Violated Rules: ['2.2']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 626
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:19.852680Z",
     "start_time": "2024-05-11T15:01:19.851561Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 626
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
