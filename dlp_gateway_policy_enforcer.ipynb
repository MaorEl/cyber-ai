{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.157334Z",
     "start_time": "2024-05-11T15:01:01.748106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Efraim\n",
      "[nltk_data]     Yosofov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import spacy \n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "import dataclasses\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "USE_CACHE_DICTS = True # set to False to recompute all dictionaries\n",
    "\n",
    "# # Read dictionary pkl file\n",
    "# with open('email_to_departments.pkl', 'rb') as fp:\n",
    "#     email_to_departments = pickle.load(fp)\n",
    "#     print('email_to_departments dictionary loaded from pkl file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.767303Z",
     "start_time": "2024-05-11T15:01:02.158816Z"
    }
   },
   "outputs": [],
   "source": [
    "enron_df = pd.read_pickle('enron_students.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.904957Z",
     "start_time": "2024-05-11T15:01:02.768028Z"
    }
   },
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "enron_df['To'] = enron_df['To'].fillna('')\n",
    "enron_df['From'] = enron_df['From'].fillna('')\n",
    "enron_df['X-From'] = enron_df['X-From'].fillna('')\n",
    "enron_df['X-To'] = enron_df['X-To'].fillna('')\n",
    "enron_df['X-cc'] = enron_df['X-cc'].fillna('')\n",
    "enron_df['X-bcc'] = enron_df['X-bcc'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.909514Z",
     "start_time": "2024-05-11T15:01:02.906086Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_emails(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # Regex to match email addresses\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    return re.findall(email_pattern, text)\n",
    "\n",
    "def extract_single_email_from_text(text):\n",
    "    emails = extract_emails(text)\n",
    "    if (len(emails) > 1):\n",
    "        print(f\"Multiple emails found in: {text}\")\n",
    "    elif len(emails) == 1:\n",
    "        return emails[0]\n",
    "    print(f\"Could not extract email from: {text}\")\n",
    "    return None\n",
    "\n",
    "def extract_sent_to_emails(text):\n",
    "    emails = extract_emails(text)\n",
    "    if len(emails) > 0:\n",
    "        return emails\n",
    "    return []\n",
    "\n",
    "def is_between_ect_and_ees(email_to_depart_dict, row, is_including_cc_bcc=False, additional_check=True):\n",
    "    sender_email = extract_single_email_from_text(row['From'])\n",
    "    if sender_email in email_to_depart_dict:\n",
    "        sender_department = email_to_depart_dict[sender_email]\n",
    "        if sender_department != 'ECT' and sender_department != 'EES':\n",
    "            return False\n",
    "        else:\n",
    "            if is_including_cc_bcc:\n",
    "                reciever_emails = extract_sent_to_emails(row['To']) + extract_sent_to_emails(row['X-To'])\n",
    "            else:\n",
    "                reciever_emails = extract_sent_to_emails(row['To']) + extract_sent_to_emails(row['X-To']) + extract_sent_to_emails(row['X-cc']) + extract_sent_to_emails(row['X-bcc'])\n",
    "            \n",
    "            for email in reciever_emails:\n",
    "                if email in email_to_depart_dict:\n",
    "                    reciever_department = email_to_depart_dict[email]\n",
    "\n",
    "                    if sender_department == 'ECT' and reciever_department == 'EES':\n",
    "                        return True\n",
    "                    elif sender_department == 'EES' and reciever_department == 'ECT':\n",
    "                        return True\n",
    "                    \n",
    "            if additional_check:\n",
    "                if 'ECT' in row['X-To']:\n",
    "                    if 'EES' in row['X-From']:\n",
    "                        return True\n",
    "                if 'EES' in row['X-To']:\n",
    "                    if 'ECT' in row['X-From']:\n",
    "                        return True\n",
    "      \n",
    "            return False\n",
    "    \n",
    "    else:\n",
    "        if additional_check:\n",
    "            if 'ECT' in row['X-To']:\n",
    "                if 'EES' in row['X-From']:\n",
    "                    return True\n",
    "            if 'EES' in row['X-To']:\n",
    "                if 'ECT' in row['X-From']:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.918666Z",
     "start_time": "2024-05-11T15:01:02.910322Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_dict():\n",
    "    email_to_departments = {}\n",
    "    email_to_departments.update({\n",
    "            'smith.day@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'stuart.zisman@enron.com' : 'ECT'\n",
    "            ,'melissa.murphy@enron.com' : 'ECT'\n",
    "            ,'thresa.allen@enron.com' : 'ECT'\n",
    "            ,'leslie.reeves@enron.com' : 'ECT'\n",
    "            ,'stacey.white@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'brad.nebergall@enron.com': 'ECT'\n",
    "            ,'colleen.koenig@enron.com': 'EES'\n",
    "            ,'john.kinser@enron.com': 'ECT'\n",
    "            ,'jeff.merola@enron.com': 'EES'\n",
    "            })\n",
    "    \n",
    "    email_to_departments.update({'eric.bass@enron.com': 'ECT'})\n",
    "\n",
    "    multiple_count = 0\n",
    "    for index, row in enron_df.iterrows():\n",
    "        x_emails = extract_emails(row['X-From'])\n",
    "        from_emails = set([mail.lower() for mail in (extract_emails(row['From']) + x_emails)])\n",
    "        to_emails = set([mail.lower() for mail in (extract_emails(row['To']) + extract_emails(row['X-To']))])\n",
    "        if len(from_emails) == 0:\n",
    "            continue\n",
    "        if len(from_emails) > 1:\n",
    "            from_emails = [mail for mail in from_emails if not mail.startswith('imceanotes')]\n",
    "            if len(from_emails) > 1 or len(from_emails) == 0:\n",
    "                multiple_count += 1\n",
    "\n",
    "        for email in from_emails:\n",
    "            email = email.lower()\n",
    "            if \"enron.com\" not in email and email not in email_to_departments:\n",
    "                email_to_departments.update({email: 'NA'})\n",
    "            else:\n",
    "                if email in email_to_departments and email_to_departments[email] != 'Other':\n",
    "                    continue\n",
    "                elif 'EES' in row['X-From']:\n",
    "                    email_to_departments.update({email: 'EES'})\n",
    "                    if len(to_emails) == 1:\n",
    "                        email_to_departments.update({list(to_emails)[0]: 'ECT'})\n",
    "                elif 'ECT' in row['X-From']:\n",
    "                    email_to_departments.update({email: 'ECT'})\n",
    "                    if len(to_emails) == 1:\n",
    "                        email_to_departments.update({list(to_emails)[0]: 'EES'})\n",
    "                else:\n",
    "                    email_to_departments.update({email: 'Other'})\n",
    "\n",
    "        # new addition - need to check\n",
    "        if len(to_emails) == 1:\n",
    "            if 'ECT' in row['X-To']:\n",
    "                email_to_departments.update({list(to_emails)[0]: 'ECT'})\n",
    "            elif 'EES' in row['X-To']:\n",
    "                email_to_departments.update({list(to_emails)[0]: 'EES'})\n",
    "\n",
    "    email_to_departments.update({\n",
    "            'smith.day@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'stuart.zisman@enron.com' : 'ECT'\n",
    "            ,'melissa.murphy@enron.com' : 'ECT'\n",
    "            ,'thresa.allen@enron.com' : 'ECT'\n",
    "            ,'leslie.reeves@enron.com' : 'ECT'\n",
    "            ,'stacey.white@enron.com' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'brad.nebergall@enron.com': 'ECT'\n",
    "            ,'colleen.koenig@enron.com': 'EES'\n",
    "            ,'john.kinser@enron.com': 'ECT'\n",
    "            ,'jeff.merola@enron.com\t': 'EES'\n",
    "            ,'scott.mills@enron.com': 'ECT'\n",
    "            ,'marilyn.colbert@enron.com': 'ECT'\n",
    "            ,'molly.harris@enron.com': 'ECT'\n",
    "            ,'joseph.wagner@enron.com': 'ECT'\n",
    "            ,'stuart.zisman@enron.com,' : 'ECT'\n",
    "            ,'janet.wallis@enron.com' : 'ECT'\n",
    "            ,'daren.farmer@enron.com' : 'ECT'\n",
    "            ,'stephanie.gardner@enron.com' : 'EES'\n",
    "\n",
    "            })\n",
    "    \n",
    "    return email_to_departments\n",
    "\n",
    "if USE_CACHE_DICTS:\n",
    "    email_to_department_dict = pickle.load(open('email_to_departments.pkl', 'rb'))\n",
    "else:\n",
    "    email_to_department_dict = build_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:02.920964Z",
     "start_time": "2024-05-11T15:01:02.919277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20638"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(email_to_department_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.213634Z",
     "start_time": "2024-05-11T15:01:02.921457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not extract email from: u@d.h\n",
      "Could not extract email from: pep <performance.>\n"
     ]
    }
   ],
   "source": [
    "enron_df['is_between_ect_and_ees'] = enron_df.apply(lambda row: is_between_ect_and_ees(email_to_department_dict, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.215880Z",
     "start_time": "2024-05-11T15:01:06.214310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 'cheryl.dudley@enron.com' in email_to_department_dict:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.484514Z",
     "start_time": "2024-05-11T15:01:06.216431Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove all spaces \n",
    "enron_df['violated_rules'] = enron_df['violated_rules'].apply(lambda x: x.replace(' ', ''))\n",
    "\n",
    "# apply split ',' on violated rules\n",
    "enron_df['violated_rules'] = enron_df['violated_rules'].apply(lambda x: x.split(',')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.636397Z",
     "start_time": "2024-05-11T15:01:06.486491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>Subject</th>\n",
       "      <th>email_body</th>\n",
       "      <th>verdict</th>\n",
       "      <th>violated_rules</th>\n",
       "      <th>is_between_ect_and_ees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349726</th>\n",
       "      <td>Wed, 6 Jun 2001 13:03:00 -0700 (PDT)</td>\n",
       "      <td>randal.maffett@enron.com</td>\n",
       "      <td>don.schroeder@enron.com, patrick.danaher@enron.com, adam.metry@enron.com, \\n\\tsarah.mulholland@enron.com, bill.briggs@enron.com, \\n\\tgerald.nemec@enron.com, lisa.vitali@enron.com, bill.white@enron.com, \\n\\tjames.gough@enron.com, jim.goughary@enron.com, john.wilson@enron.com</td>\n",
       "      <td>Don Schroeder &lt;Don Schroeder/ENRON@enronXgate&gt;, Patrick Danaher &lt;Patrick Danaher/NA/Enron@Enron&gt;, Adam Metry &lt;Adam Metry/ENRON@enronXgate&gt;, Sarah Mulholland &lt;Sarah Mulholland/ENRON@enronXgate&gt;, Bill F Briggs &lt;Bill F Briggs/ENRON@enronXgate&gt;, Gerald Nemec &lt;Gerald Nemec/HOU/ECT@ECT&gt;, Lisa Vitali &lt;Lisa Vitali/ENRON@enronXgate&gt;, White@ &lt;White@/O==ENRON/OU==NA/CN==RECIPIENTS/CN==JWHITE7@EX@enronXgate&gt;, Bill White &lt;Bill White/LON/ECT@ECT&gt;, James Gough &lt;James Gough/Enron@EUEnronXgate&gt;, Jim Goughary &lt;Jim Goughary/ENRON@enronXgate&gt;, John L Wilson &lt;John L Wilson/ENRON@enronXgate&gt;</td>\n",
       "      <td>Randal Maffett &lt;Randal Maffett/ENRON@enronXgate@ENRON&gt;</td>\n",
       "      <td>John L Nowlan &lt;John L Nowlan/ENRON@enronXgate&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Kurt Wipp trip to Houston</td>\n",
       "      <td>Kurt Wipp is a recent hire in our London office to focus on origination/mid-market opps.  Kurt joins us after 15+ yrs w/ Methanex.  I've asked him to spend next week or so in Houston introducing himself to all the traders, originators, finance, RAC, Legal, etc...  I have given him most of your names and he will probably be contacting you to try and set up some time to meet.  My assistant, Beth Ryan, may also be coordinating some of the meetings.  Please take time to visit w/ him, even if only briefly and help him better understand your markets, perspectives, goals and objectives.  It's important that in addition to Kurt developing an understanding of our business strategies/opportunities that he also develop and accelerate his \"Enron DNA.\"  Thanks in advance!</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498426</th>\n",
       "      <td>Thu, 10 May 2001 12:49:00 -0700 (PDT)</td>\n",
       "      <td>john.kiani@enron.com</td>\n",
       "      <td>v.weldon@enron.com</td>\n",
       "      <td>V Charles Weldon &lt;V Charles Weldon/HOU/ECT@ECT&gt;</td>\n",
       "      <td>John Kiani &lt;John Kiani/ENRON@enronXgate@ENRON&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Stagecoach Contract</td>\n",
       "      <td>Charlie,\\n\\nHere is the Stagecoach contract that I promised you.  Let me know if you have any questions.\\n\\nRegards,\\n\\nJohn\\n\\n</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Date                      From  \\\n",
       "349726   Wed, 6 Jun 2001 13:03:00 -0700 (PDT)  randal.maffett@enron.com   \n",
       "498426  Thu, 10 May 2001 12:49:00 -0700 (PDT)      john.kiani@enron.com   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                        To  \\\n",
       "349726  don.schroeder@enron.com, patrick.danaher@enron.com, adam.metry@enron.com, \\n\\tsarah.mulholland@enron.com, bill.briggs@enron.com, \\n\\tgerald.nemec@enron.com, lisa.vitali@enron.com, bill.white@enron.com, \\n\\tjames.gough@enron.com, jim.goughary@enron.com, john.wilson@enron.com   \n",
       "498426                                                                                                                                                                                                                                                                  v.weldon@enron.com   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    X-To  \\\n",
       "349726  Don Schroeder <Don Schroeder/ENRON@enronXgate>, Patrick Danaher <Patrick Danaher/NA/Enron@Enron>, Adam Metry <Adam Metry/ENRON@enronXgate>, Sarah Mulholland <Sarah Mulholland/ENRON@enronXgate>, Bill F Briggs <Bill F Briggs/ENRON@enronXgate>, Gerald Nemec <Gerald Nemec/HOU/ECT@ECT>, Lisa Vitali <Lisa Vitali/ENRON@enronXgate>, White@ <White@/O==ENRON/OU==NA/CN==RECIPIENTS/CN==JWHITE7@EX@enronXgate>, Bill White <Bill White/LON/ECT@ECT>, James Gough <James Gough/Enron@EUEnronXgate>, Jim Goughary <Jim Goughary/ENRON@enronXgate>, John L Wilson <John L Wilson/ENRON@enronXgate>   \n",
       "498426                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   V Charles Weldon <V Charles Weldon/HOU/ECT@ECT>   \n",
       "\n",
       "                                                        X-From  \\\n",
       "349726  Randal Maffett <Randal Maffett/ENRON@enronXgate@ENRON>   \n",
       "498426          John Kiani <John Kiani/ENRON@enronXgate@ENRON>   \n",
       "\n",
       "                                                  X-cc X-bcc  \\\n",
       "349726  John L Nowlan <John L Nowlan/ENRON@enronXgate>         \n",
       "498426                                                         \n",
       "\n",
       "                          Subject  \\\n",
       "349726  Kurt Wipp trip to Houston   \n",
       "498426        Stagecoach Contract   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               email_body  \\\n",
       "349726  Kurt Wipp is a recent hire in our London office to focus on origination/mid-market opps.  Kurt joins us after 15+ yrs w/ Methanex.  I've asked him to spend next week or so in Houston introducing himself to all the traders, originators, finance, RAC, Legal, etc...  I have given him most of your names and he will probably be contacting you to try and set up some time to meet.  My assistant, Beth Ryan, may also be coordinating some of the meetings.  Please take time to visit w/ him, even if only briefly and help him better understand your markets, perspectives, goals and objectives.  It's important that in addition to Kurt developing an understanding of our business strategies/opportunities that he also develop and accelerate his \"Enron DNA.\"  Thanks in advance!   \n",
       "498426                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Charlie,\\n\\nHere is the Stagecoach contract that I promised you.  Let me know if you have any questions.\\n\\nRegards,\\n\\nJohn\\n\\n     \n",
       "\n",
       "       verdict violated_rules  is_between_ect_and_ees  \n",
       "349726   BLOCK          [1.1]                   False  \n",
       "498426   BLOCK          [1.1]                   False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "enron_df_not_catched_1_1 = enron_df[(enron_df['is_between_ect_and_ees'] == False) & (enron_df['violated_rules'].apply(lambda x: '1.1' in x ) & (enron_df['X-To'].str.contains('ECT')))]\n",
    "enron_df_not_catched_1_1.head(10)\n",
    "# len(enron_df_not_catched_1_1)\n",
    "\n",
    "# print(is_between_ect_and_ees(test, enron_df_not_catched_1_1.iloc[0], False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.640018Z",
     "start_time": "2024-05-11T15:01:06.636984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 0 emails\n"
     ]
    }
   ],
   "source": [
    "def update_dict(enron_df_not_catched_1_1, email_to_depart):\n",
    "    # iterate over the rows of the dataframe enron_df_not_catched_1_1\n",
    "    updated = 0\n",
    "    for index, row in enron_df_not_catched_1_1.iterrows():\n",
    "        x_emails = extract_emails(row['X-From'])\n",
    "        emails = set([mail.lower() for mail in (extract_emails(row['From']) + x_emails)])\n",
    "        sent_to_emails = extract_sent_to_emails(row['To']) + extract_sent_to_emails(row['X-To'])\n",
    "        if len(emails) == 0:\n",
    "            continue\n",
    "        if len(emails) > 1:\n",
    "            emails = [mail for mail in emails if not mail.startswith('imceanotes')]\n",
    "            if len(emails) > 1 or len(emails) == 0:\n",
    "                # print(f\"From: {row['From']} X-From: {row['X-From']} has multiple emails: {emails}\")\n",
    "                continue\n",
    "        for email in emails:\n",
    "            email = email.lower()\n",
    "            # if from email is in dictionary, get the department\n",
    "            if email in email_to_depart:\n",
    "                depart = email_to_depart[email]\n",
    "                if depart == 'ECT':\n",
    "                    if len(sent_to_emails) == 1:\n",
    "                        email_to_depart[sent_to_emails[0]] = 'EES'\n",
    "                        updated += 1\n",
    "                elif depart == 'EES':\n",
    "                    if len(sent_to_emails) == 1:\n",
    "                        email_to_depart[sent_to_emails[0]] = 'ECT'\n",
    "                        updated += 1\n",
    "\n",
    "    print(f\"Updated {updated} emails\")\n",
    "    \n",
    "\n",
    "\n",
    "update_dict(enron_df_not_catched_1_1, email_to_department_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HERE WE START USER TO LOCATION *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.644746Z",
     "start_time": "2024-05-11T15:01:06.640649Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_email_to_location_dict(df):\n",
    "    email_to_location = {}\n",
    "    for index, row in enron_df.iterrows():\n",
    "        x_emails = extract_emails(row['X-From'])\n",
    "        from_emails = set([mail.lower() for mail in (extract_emails(row['From']) + x_emails)])\n",
    "        if '/OU=EU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'EU'})\n",
    "        elif '/HOU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "        elif '/OU=NA/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "\n",
    "    # iterate over the dataframe to get \n",
    "    violated_rule_1_2 = df[df['violated_rules'].apply(lambda x: '1.2' in x)]\n",
    "\n",
    "    for index, row in violated_rule_1_2.iterrows():\n",
    "        from_emails = extract_emails(row['X-From'])\n",
    "        from_emails = list(set([mail.lower() for mail in (extract_emails(row['From']) + from_emails)]))\n",
    "        if '/OU=EU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'EU'})\n",
    "        elif '/HOU/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "        elif '/OU=NA/' in row['X-From']:\n",
    "            for email in from_emails:\n",
    "                email_to_location.update({email: 'NA'})\n",
    "        \n",
    "        sent_to_email = extract_emails(row['X-To'])\n",
    "        if len(sent_to_email) == 1:\n",
    "            if from_emails[0] not in email_to_location:\n",
    "                continue\n",
    "            if email_to_location[from_emails[0]] == 'EU':\n",
    "                email_to_location.update({sent_to_email[0]: 'NA'})\n",
    "            elif email_to_location[from_emails[0]] == 'NA':\n",
    "                email_to_location.update({sent_to_email[0]: 'EU'})\n",
    "            \n",
    "    return email_to_location\n",
    "\n",
    "if USE_CACHE_DICTS:\n",
    "    email_to_location = pickle.load(open('email_to_location.pkl', 'rb'))\n",
    "else:\n",
    "    email_to_location = get_email_to_location_dict(enron_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:06.647356Z",
     "start_time": "2024-05-11T15:01:06.645336Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_between_EU_and_NA(row, email_to_location):\n",
    "    from_email = extract_emails(row['From'])\n",
    "    from_email = extract_emails(row['X-From']) + from_email\n",
    "    from_email = list(set([mail.lower() for mail in from_email]))\n",
    "    to_email = extract_emails(row['To'])\n",
    "    to_email = extract_emails(row['X-To']) + to_email\n",
    "    to_email = list(set([mail.lower() for mail in to_email]))\n",
    "    if len(from_email) == 0 or len(to_email) == 0:\n",
    "        return False\n",
    "    if from_email[0] in email_to_location:\n",
    "        if email_to_location[from_email[0]] == 'EU':\n",
    "            for email in to_email:\n",
    "                if email in email_to_location and email_to_location[email] == 'NA':\n",
    "                    return True\n",
    "        if email_to_location[from_email[0]] == 'NA':\n",
    "            for email in to_email:\n",
    "                if email in email_to_location and email_to_location[email] == 'EU':\n",
    "                    return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.842986Z",
     "start_time": "2024-05-11T15:01:06.647925Z"
    }
   },
   "outputs": [],
   "source": [
    "enron_df['is_EU_To_NA'] = enron_df.apply(lambda row: is_between_EU_and_NA(row, email_to_location), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.889621Z",
     "start_time": "2024-05-11T15:01:11.843583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>Subject</th>\n",
       "      <th>email_body</th>\n",
       "      <th>verdict</th>\n",
       "      <th>violated_rules</th>\n",
       "      <th>is_between_ect_and_ees</th>\n",
       "      <th>is_EU_To_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>Mon, 4 Dec 2000 23:08:00 -0800 (PST)</td>\n",
       "      <td>craig.brown@enron.com</td>\n",
       "      <td>heidi.smith@enron.com</td>\n",
       "      <td>Heidi Smith</td>\n",
       "      <td>Craig H Brown</td>\n",
       "      <td>Jeff Youngflesh, Jennifer Medcalf</td>\n",
       "      <td></td>\n",
       "      <td>Re: Vulcan Signs</td>\n",
       "      <td>Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>Tue, 12 Dec 2000 11:33:00 -0800 (PST)</td>\n",
       "      <td>eric.letke@enron.com</td>\n",
       "      <td>jennifer.medcalf@enron.com, william.bradford@enron.com</td>\n",
       "      <td>Jennifer Medcalf, William S Bradford</td>\n",
       "      <td>Eric Letke</td>\n",
       "      <td>James M Wood, John Woodman, Greg Sharp, Robert Greer</td>\n",
       "      <td></td>\n",
       "      <td>Urgent - Sony</td>\n",
       "      <td>Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>Tue, 12 Dec 2000 11:33:00 -0800 (PST)</td>\n",
       "      <td>eric.letke@enron.com</td>\n",
       "      <td>jennifer.medcalf@enron.com, william.bradford@enron.com</td>\n",
       "      <td>Jennifer Medcalf, William S Bradford</td>\n",
       "      <td>Eric Letke</td>\n",
       "      <td>James M Wood, John Woodman, Greg Sharp, Robert Greer</td>\n",
       "      <td></td>\n",
       "      <td>Urgent - Sony</td>\n",
       "      <td>Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>Mon, 4 Dec 2000 23:08:00 -0800 (PST)</td>\n",
       "      <td>craig.brown@enron.com</td>\n",
       "      <td>heidi.smith@enron.com</td>\n",
       "      <td>Heidi Smith</td>\n",
       "      <td>Craig H Brown</td>\n",
       "      <td>Jeff Youngflesh, Jennifer Medcalf</td>\n",
       "      <td></td>\n",
       "      <td>Re: Vulcan Signs</td>\n",
       "      <td>Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12190</th>\n",
       "      <td>Mon, 4 Dec 2000 08:19:00 -0800 (PST)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>luis.mena@enron.com</td>\n",
       "      <td>Luis Mena</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td>Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins</td>\n",
       "      <td></td>\n",
       "      <td>Re: FYI</td>\n",
       "      <td>You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15572</th>\n",
       "      <td>Mon, 4 Dec 2000 08:19:00 -0800 (PST)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>luis.mena@enron.com</td>\n",
       "      <td>Luis Mena</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td>Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins</td>\n",
       "      <td></td>\n",
       "      <td>Re: FYI</td>\n",
       "      <td>You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18070</th>\n",
       "      <td>Thu, 10 May 2001 02:41:00 -0700 (PDT)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com</td>\n",
       "      <td>Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rotation</td>\n",
       "      <td>I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18918</th>\n",
       "      <td>Thu, 10 May 2001 02:41:00 -0700 (PDT)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com</td>\n",
       "      <td>Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia</td>\n",
       "      <td>Bryan Hull</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rotation</td>\n",
       "      <td>I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19169</th>\n",
       "      <td>Thu, 10 May 2001 12:41:00 -0700 (PDT)</td>\n",
       "      <td>bryan.hull@enron.com</td>\n",
       "      <td>don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com</td>\n",
       "      <td>Don Baughman &lt;Don Baughman/HOU/ECT@ECT&gt;, Juan Hernandez &lt;Juan Hernandez/Corp/Enron@ENRON&gt;, Rudy Acevedo &lt;Rudy Acevedo/HOU/ECT@ECT&gt;, Chad Starnes &lt;Chad Starnes/Corp/Enron@Enron&gt;, Miguel L Garcia &lt;Miguel L Garcia/NA/Enron@ENRON&gt;</td>\n",
       "      <td>Bryan Hull &lt;Bryan Hull/ENRON@enronXgate@ENRON&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rotation</td>\n",
       "      <td>I want to thank all of you for taking the time to meet with me about the hourly desk trading position.  Unfortunately, I have to withdraw my name from consideration.  I have accepted a position working on the Texas Gas Trading desk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2, 2.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19432</th>\n",
       "      <td>Mon, 12 Nov 2001 07:44:35 -0800 (PST)</td>\n",
       "      <td>daniel.muschar@enron.com</td>\n",
       "      <td>don.baughman@enron.com, jae.black@enron.com, lloyd.will@enron.com</td>\n",
       "      <td>Baughman Jr., Don &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dbaughm&gt;, Black, Tamara Jae &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tblack&gt;, Will, Lloyd &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lwill&gt;</td>\n",
       "      <td>Muschar, Daniel &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=DMUSCHA&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>24 hr 1-800 phone</td>\n",
       "      <td>TJ:\\n\\nHow many 1-800 phone numbers does power have? ( If any other than 24 Hr trading, please advise)\\nWhat is the number for 24 HR group? ( I will need to coordinate a cutover for this)\\nDo you know of any special phone needs for the weekend trading?  (The people on turrets will be fine, they pin in anywhere)\\n\\nAny other thoughts or concerns are appreciated.\\n\\nThank you,\\n\\nDaniel A. Muschar\\nECS Project Team Lead\\nOffice: 713-853-4344\\nCell: 281-541-6203\\ndaniel.muschar@enron.com\\nCCNA, MCSE, CNA, A+</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Date                      From  \\\n",
       "4207    Mon, 4 Dec 2000 23:08:00 -0800 (PST)     craig.brown@enron.com   \n",
       "4790   Tue, 12 Dec 2000 11:33:00 -0800 (PST)      eric.letke@enron.com   \n",
       "7899   Tue, 12 Dec 2000 11:33:00 -0800 (PST)      eric.letke@enron.com   \n",
       "7929    Mon, 4 Dec 2000 23:08:00 -0800 (PST)     craig.brown@enron.com   \n",
       "12190   Mon, 4 Dec 2000 08:19:00 -0800 (PST)      bryan.hull@enron.com   \n",
       "15572   Mon, 4 Dec 2000 08:19:00 -0800 (PST)      bryan.hull@enron.com   \n",
       "18070  Thu, 10 May 2001 02:41:00 -0700 (PDT)      bryan.hull@enron.com   \n",
       "18918  Thu, 10 May 2001 02:41:00 -0700 (PDT)      bryan.hull@enron.com   \n",
       "19169  Thu, 10 May 2001 12:41:00 -0700 (PDT)      bryan.hull@enron.com   \n",
       "19432  Mon, 12 Nov 2001 07:44:35 -0800 (PST)  daniel.muschar@enron.com   \n",
       "\n",
       "                                                                                                                                  To  \\\n",
       "4207                                                                                                           heidi.smith@enron.com   \n",
       "4790                                                                          jennifer.medcalf@enron.com, william.bradford@enron.com   \n",
       "7899                                                                          jennifer.medcalf@enron.com, william.bradford@enron.com   \n",
       "7929                                                                                                           heidi.smith@enron.com   \n",
       "12190                                                                                                            luis.mena@enron.com   \n",
       "15572                                                                                                            luis.mena@enron.com   \n",
       "18070  don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com   \n",
       "18918  don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com   \n",
       "19169  don.baughman@enron.com, juan.hernandez@enron.com, rudy.acevedo@enron.com, \\n\\tchad.starnes@enron.com, miguel.garcia@enron.com   \n",
       "19432                                                              don.baughman@enron.com, jae.black@enron.com, lloyd.will@enron.com   \n",
       "\n",
       "                                                                                                                                                                                                                                     X-To  \\\n",
       "4207                                                                                                                                                                                                                          Heidi Smith   \n",
       "4790                                                                                                                                                                                                 Jennifer Medcalf, William S Bradford   \n",
       "7899                                                                                                                                                                                                 Jennifer Medcalf, William S Bradford   \n",
       "7929                                                                                                                                                                                                                          Heidi Smith   \n",
       "12190                                                                                                                                                                                                                           Luis Mena   \n",
       "15572                                                                                                                                                                                                                           Luis Mena   \n",
       "18070                                                                                                                                                           Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia   \n",
       "18918                                                                                                                                                           Don Baughman, Juan Hernandez, Rudy Acevedo, Chad Starnes, Miguel L Garcia   \n",
       "19169  Don Baughman <Don Baughman/HOU/ECT@ECT>, Juan Hernandez <Juan Hernandez/Corp/Enron@ENRON>, Rudy Acevedo <Rudy Acevedo/HOU/ECT@ECT>, Chad Starnes <Chad Starnes/Corp/Enron@Enron>, Miguel L Garcia <Miguel L Garcia/NA/Enron@ENRON>   \n",
       "19432                                                        Baughman Jr., Don </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dbaughm>, Black, Tamara Jae </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tblack>, Will, Lloyd </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lwill>   \n",
       "\n",
       "                                                          X-From  \\\n",
       "4207                                               Craig H Brown   \n",
       "4790                                                  Eric Letke   \n",
       "7899                                                  Eric Letke   \n",
       "7929                                               Craig H Brown   \n",
       "12190                                                 Bryan Hull   \n",
       "15572                                                 Bryan Hull   \n",
       "18070                                                 Bryan Hull   \n",
       "18918                                                 Bryan Hull   \n",
       "19169             Bryan Hull <Bryan Hull/ENRON@enronXgate@ENRON>   \n",
       "19432  Muschar, Daniel </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DMUSCHA>   \n",
       "\n",
       "                                                                            X-cc  \\\n",
       "4207                                           Jeff Youngflesh, Jennifer Medcalf   \n",
       "4790                        James M Wood, John Woodman, Greg Sharp, Robert Greer   \n",
       "7899                        James M Wood, John Woodman, Greg Sharp, Robert Greer   \n",
       "7929                                           Jeff Youngflesh, Jennifer Medcalf   \n",
       "12190  Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins   \n",
       "15572  Timothy Blanchard, Eric Bass, Chad Landry, Matthew Lenhart, Brian Hoskins   \n",
       "18070                                                                              \n",
       "18918                                                                              \n",
       "19169                                                                              \n",
       "19432                                                                              \n",
       "\n",
       "      X-bcc            Subject  \\\n",
       "4207          Re: Vulcan Signs   \n",
       "4790             Urgent - Sony   \n",
       "7899             Urgent - Sony   \n",
       "7929          Re: Vulcan Signs   \n",
       "12190                  Re: FYI   \n",
       "15572                  Re: FYI   \n",
       "18070                 Rotation   \n",
       "18918                 Rotation   \n",
       "19169                 Rotation   \n",
       "19432        24 hr 1-800 phone   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    email_body  \\\n",
       "4207   Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...   \n",
       "4790                                                                                                                                                                                                                               Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?   \n",
       "7899                                                                                                                                                                                                                               Bill, were you able to talk with Sony's Treasurer today?  As you know, we \\nhave a Friday deadline that is fast approaching.  We have a call with the San \\nDiego team tomorrow and I would like to have an update ready for them.  \\nPlease page me at 888-766-4103 to give me an update.\\n\\nNot sure if you were aware of 2 items that Jennifer passed on to me:  1.)  We \\nas EES have recently signed a confidentiality agreement with Sony.  2.)  \\nSony's web site has alot of financial numbers (I don't know if they are \\nbroken-out).\\n\\nAlso, we are preparing for alternative S-T solutions.  How many months are \\nyou willing to allow at this point (we are coming off a 4 month deal) and if \\nwe do a PX plus basis deal (reduced market exposure) does that change our \\nposition at all?   \n",
       "7929   Heidi:\\n\\nPlease outline the Vulcan contract for Jeff and Jennifer.  They also have \\ndevelopment questions as to their market capability of metals.  Please call \\nLenard at Vulcan and see what is the type, grade and volumes they purchase.  \\nWe may be able to provide additional leverage to their purchases.\\n\\nThanks,\\n\\nCraig\\n----- Forwarded by Craig H Brown/NA/Enron on 12/05/2000 07:03 AM -----\\n\\n\\tJennifer Medcalf\\n\\t12/05/2000 12:00 AM\\n\\t\\t\\n\\t\\t To: Jeff Youngflesh/NA/Enron\\n\\t\\t cc: Colleen Koenig/NA/Enron@Enron, Craig H Brown/NA/Enron@Enron, Daniel \\nColeman/NA/Enron@Enron, Sarah-Joy Hunter/NA/Enron@Enron\\n\\t\\t Subject: Re: Vulcan Signs\\n\\nJeff,\\nPlease investigate this company and see if there  are additional Enron \\nproducts and services like metals that might be of interest.  They are a \\npretty small gas user but there might be greater prospects in other areas.  \\nWhat is the value of the contract that we have entered with them?\\nJennifer Stewart Medcalf\\nSenior Direc...   \n",
       "12190  You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...   \n",
       "15572  You need more to do.\\n\\n\\n\\n\\nLuis Mena@ENRON\\n12/04/2000 04:13 PM\\nTo: Timothy Blanchard/HOU/EES@EES\\ncc: Eric Bass/HOU/ECT@ECT@EES, Chad Landry/HOU/ECT@ECT@EES, Matthew \\nLenhart/HOU/ECT@ECT@EES, Bryan Hull/HOU/ECT@ECT@EES, Brian Hoskins/Enron \\nCommunications@Enron Communications@EES \\nSubject: Re: FYI  \\n\\nSpeaking of SEC dominance, Brian and I made a 100 dollar bet this weekend.  \\nWho had more football titles, the teams in the SEC or the teams in the Big \\n12????\\n\\nWell, after analyzing the data for the past hour, and analyzing every poll \\nevery which way, there is no doubt about it now.  I counted each single poll \\nindividually (AP, the National Football Foundation and College Football Hall \\nof Fame, the United Press, the Football Writers Polls and the USA Today/ESPN) \\nand every poll gives more championships to the Big 12 than the SEC.\\n\\nSince college football is all about rivalries and drinking, Eric and I will \\nbe hosting a \"The SEC is definitely better than the BIG...   \n",
       "18070                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195   \n",
       "18918                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I want to thank all of you for taking the time to meet with me about the \\nhourly desk trading position.  Unfortunately, I have to withdraw my name from \\nconsideration.  I have accepted a position working on the Texas Gas Trading \\ndesk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195   \n",
       "19169                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I want to thank all of you for taking the time to meet with me about the hourly desk trading position.  Unfortunately, I have to withdraw my name from consideration.  I have accepted a position working on the Texas Gas Trading desk.  \\n\\nThanks,\\n\\nBryan Hull\\nEnronOnline\\n713-853-9195   \n",
       "19432                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           TJ:\\n\\nHow many 1-800 phone numbers does power have? ( If any other than 24 Hr trading, please advise)\\nWhat is the number for 24 HR group? ( I will need to coordinate a cutover for this)\\nDo you know of any special phone needs for the weekend trading?  (The people on turrets will be fine, they pin in anywhere)\\n\\nAny other thoughts or concerns are appreciated.\\n\\nThank you,\\n\\nDaniel A. Muschar\\nECS Project Team Lead\\nOffice: 713-853-4344\\nCell: 281-541-6203\\ndaniel.muschar@enron.com\\nCCNA, MCSE, CNA, A+   \n",
       "\n",
       "      verdict violated_rules  is_between_ect_and_ees  is_EU_To_NA  \n",
       "4207    BLOCK     [1.2, 2.1]                   False        False  \n",
       "4790    BLOCK          [1.2]                   False        False  \n",
       "7899    BLOCK          [1.2]                   False        False  \n",
       "7929    BLOCK     [1.2, 2.1]                   False        False  \n",
       "12190   BLOCK          [1.2]                    True        False  \n",
       "15572   BLOCK          [1.2]                    True        False  \n",
       "18070   BLOCK     [1.2, 2.1]                   False        False  \n",
       "18918   BLOCK     [1.2, 2.1]                   False        False  \n",
       "19169   BLOCK     [1.2, 2.1]                   False        False  \n",
       "19432   BLOCK          [1.2]                   False        False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_working = enron_df[(enron_df['is_EU_To_NA'] == False) & (enron_df['violated_rules'].apply(lambda x: '1.2' in x))]\n",
    "not_working.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.891803Z",
     "start_time": "2024-05-11T15:01:11.890299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3985\n"
     ]
    }
   ],
   "source": [
    "print(len(email_to_location))\n",
    "# enron_df.head(10)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.895526Z",
     "start_time": "2024-05-11T15:01:11.892466Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_c_suit_dict():\n",
    "    emails = set({\n",
    "        'kenneth.lay@enron.com',\n",
    "        'ken.skilling@enron.com',\n",
    "        'rbowers@nyiso.com',\n",
    "        'michael.brown@enron.com',\n",
    "        'john.sherriff@enron.com',\n",
    "        'jeffrey.sherrick@enron.com',\n",
    "        'a..shankman@enron.com',\n",
    "        'ken.rice@enron.com',\n",
    "        'greg.piper@enron.com',\n",
    "        'mark.metts@enron.com',\n",
    "        'coo.jeff@enron.com',\n",
    "        'rebecca.mcdonald@enron.com',\n",
    "        'danny.mccarty@enron.com',\n",
    "        'dan.leff@enron.com',\n",
    "        'john.lavorato@enron.com',\n",
    "        'mark.koenig@enron.com',\n",
    "        'louise.kitchen@enron.com',\n",
    "        'stanley.horton@enron.com',\n",
    "        '40enron@enron.com', # for some reason is tagged for stanley horton\n",
    "        'ben.glisan@enron.com',\n",
    "        'mark.frevert@enron.com',\n",
    "        'andrew.fastow@enron.com',\n",
    "        'jr..legal@enron.com',\n",
    "        'derrick@enron.com',\n",
    "        'david.delainey@enron.com',\n",
    "        'richard.causey@enron.com',\n",
    "        'michael.brown@enron.com',\n",
    "        'raymond.bowen@enron.com',\n",
    "    })\n",
    "\n",
    "    violated_rule_1_3 = enron_df[enron_df['violated_rules'].apply(lambda x: '2.2' in x)]\n",
    "\n",
    "    for index, row in violated_rule_1_3.iterrows():\n",
    "        from_emails = extract_emails(row['X-From'])\n",
    "        from_emails = list(set([mail.lower() for mail in (extract_emails(row['From']) + from_emails)]))\n",
    "        to_email = extract_emails(row['To'])\n",
    "        to_email = extract_emails(row['X-To']) + to_email\n",
    "        to_email = list(set([mail.lower() for mail in to_email]))\n",
    "\n",
    "        if len(from_emails) == 0:\n",
    "            continue\n",
    "        for email in from_emails:\n",
    "            emails.add(email)\n",
    "            # print(f\"Email: {email} is in C-Suit\")\n",
    "\n",
    "        # for email in to_email:\n",
    "        #     emails.add(email)\n",
    "        #     print(f\"Email: {email} is in C-Suit\")\n",
    "\n",
    "    return emails\n",
    "\n",
    "if USE_CACHE_DICTS:\n",
    "    c_suit_emails = pickle.load(open('c_suit_emails.pkl', 'rb'))\n",
    "else:\n",
    "    c_suit_emails = get_c_suit_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:11.897868Z",
     "start_time": "2024-05-11T15:01:11.896027Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_in_c_suit(row, c_suit_emails):\n",
    "    # Extract and clean email addresses from 'From' fields\n",
    "    from_emails = extract_emails(row['X-From']) + extract_emails(row['From'])\n",
    "    from_emails = list(set(email.lower() for email in from_emails))\n",
    "\n",
    "    # Extract and clean email addresses from 'To' fields\n",
    "    to_email = extract_emails(row['X-To']) + extract_emails(row['To'])\n",
    "    to_email = list(set(email.lower() for email in to_email))\n",
    "\n",
    "    # Check if both sender and recipient are in the c-suite email list\n",
    "    return any(email in c_suit_emails for email in from_emails) and any(email in c_suit_emails for email in to_email)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.192452Z",
     "start_time": "2024-05-11T15:01:11.898421Z"
    }
   },
   "outputs": [],
   "source": [
    "enron_df['is_c_suit'] = enron_df.apply(lambda row: is_in_c_suit(row, c_suit_emails), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.194554Z",
     "start_time": "2024-05-11T15:01:17.193217Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.196622Z",
     "start_time": "2024-05-11T15:01:17.195045Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_from_to_emails(row):\n",
    "    from_emails = extract_emails(row['X-From']) + extract_emails(row['From'])\n",
    "    from_emails = list(set(email.lower() for email in from_emails))\n",
    "\n",
    "    # Extract and clean email addresses from 'To' fields\n",
    "    to_email = extract_emails(row['X-To']) + extract_emails(row['To'])\n",
    "    to_email = list(set(email.lower() for email in to_email))\n",
    "\n",
    "    return from_emails, to_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.199726Z",
     "start_time": "2024-05-11T15:01:17.197225Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_leaving_corporate(row):\n",
    "    from_emails, to_email = get_from_to_emails(row)\n",
    "    if len(from_emails) == 0 or len(to_email) == 0:\n",
    "        return False\n",
    "    \n",
    "    for email in to_email:\n",
    "        if 'enron.com' not in email:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_leaving_ect(row, email_to_depart):\n",
    "    from_emails, to_email = get_from_to_emails(row)\n",
    "    if len(from_emails) == 0 or len(to_email) == 0:\n",
    "        return False\n",
    "\n",
    "    for email in from_emails:\n",
    "        if email in email_to_depart and email_to_depart[email] == 'ECT':\n",
    "            for t_email in to_email:\n",
    "                if t_email in email_to_depart and email_to_depart[t_email] != 'ECT':\n",
    "                    return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.201948Z",
     "start_time": "2024-05-11T15:01:17.200249Z"
    }
   },
   "outputs": [],
   "source": [
    "# save all dictionaries as pickle\n",
    "import pickle\n",
    "global USE_CACHE_DICTS\n",
    "if not USE_CACHE_DICTS:\n",
    "    pickle.dump(email_to_location, open('email_to_location.pkl', 'wb'))\n",
    "    pickle.dump(email_to_department_dict, open('email_to_departments.pkl', 'wb'))\n",
    "    pickle.dump(c_suit_emails, open('c_suit_emails.pkl', 'wb'))\n",
    "    print('All dictionaries saved as pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.204290Z",
     "start_time": "2024-05-11T15:01:17.202485Z"
    }
   },
   "outputs": [],
   "source": [
    "class StaticAnalyzer:\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_1_1(row):\n",
    "        return is_between_ect_and_ees(email_to_department_dict, row, is_including_cc_bcc=False, additional_check=True)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_1_2(row):\n",
    "        return is_between_EU_and_NA(row, email_to_location)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_1_3(row):\n",
    "        return is_leaving_corporate(row)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_2_1(row):\n",
    "        return is_leaving_ect(row, email_to_department_dict)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_2_2(row):\n",
    "        return is_in_c_suit(row, c_suit_emails)\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_violating_rule_2_3(row):\n",
    "        return is_leaving_corporate(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.207678Z",
     "start_time": "2024-05-11T15:01:17.204776Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass()\n",
    "class ContentAnalysisResult:\n",
    "    quids: []\n",
    "    piis: []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.quids = []\n",
    "        self.piis = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'(Sensitive: {len(self.piis) > 0 or len(self.quids) > 0} | Quids: {self.quids} | PII: {self.piis})'\n",
    "    \n",
    "    def is_sensitive(self, rule_id):\n",
    "        if rule_id == '2.3':\n",
    "            return len(self.piis) > 0 or len(self.quids) >= 2\n",
    "        else:\n",
    "            return len(self.piis) > 0 or len(self.quids) > 0\n",
    "\n",
    "@dataclasses.dataclass()\n",
    "class TopicAnalysisResult:\n",
    "    is_legal: bool = False\n",
    "    is_business: bool = False\n",
    "    is_finance: bool = False\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'(Legal: {self.is_legal} | Business: {self.is_business} | Finance: {self.is_finance})'\n",
    "    \n",
    "@dataclasses.dataclass()\n",
    "class EnforcerResult:\n",
    "    violated_rules: []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.violated_rules = []\n",
    "\n",
    "    def is_allowed(self)-> bool:\n",
    "        return len(self.violated_rules) == 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Violated Rules: {self.violated_rules}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.216617Z",
     "start_time": "2024-05-11T15:01:17.208251Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_all_ssn(text):\n",
    "    return re.findall(r'\\d{3}-\\d{2}-\\d{4}', text)\n",
    "\n",
    "def find_all_credit_cards(text):\n",
    "    return re.findall(r'\\d{4}-\\d{4}-\\d{4}-\\d{4}', text) \n",
    "\n",
    "def find_all_phone_numbers(text):\n",
    "    return re.findall(r'\\(?\\d{3}\\)?\\s*-\\s*\\d{3}\\s*-\\s*\\d{4}', text) \n",
    "\n",
    "def find_sensitive_words(text):\n",
    "    return re.findall(r'password|attach|confidential', text.lower())\n",
    "\n",
    "\n",
    "class PII:\n",
    "    def __init__(self, entity_type, score, text):\n",
    "        self.entity_type = entity_type\n",
    "        self.score = score\n",
    "        self.text = text\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'(Entity: {self.entity_type} | Score: {self.score} | Text: {self.text})'\n",
    "        \n",
    "class ContentAnalyzer:\n",
    "    \n",
    "    MAX_DOC_SIZE_FOR_SPACY = 2000\n",
    "    QUIDS = ['ORG', 'GPE', 'LOW', 'FAC', 'LOC']\n",
    "    SENSITIVE = ['MONEY', 'PERCENT', 'NORP', 'PRODUCT', 'EVENT']\n",
    "    POTENTIALLY_SENSITIVE = ['DATE', 'TIME', 'QUANTITY', 'ORDINAL', 'CARDINAL', 'PERSON']\n",
    "    \n",
    "    def __init__(self, software='spacy'):      \n",
    "        self.software = software\n",
    "        if software == 'spacy':\n",
    "            self.nlp = spacy.load('en_core_web_sm')\n",
    "            self.nlp.max_length = 1500000\n",
    "        elif software == 'presidio':\n",
    "            self.analyzer = AnalyzerEngine()\n",
    "        else:\n",
    "            raise Exception(f'Software {software} is not supported')\n",
    "\n",
    "        \n",
    "    def _get_entities(self, document):\n",
    "        try:\n",
    "            doc_len = len(document)\n",
    "            if doc_len > self.MAX_DOC_SIZE_FOR_SPACY:\n",
    "                document = document[:self.MAX_DOC_SIZE_FOR_SPACY]\n",
    "            doc = self.nlp(document)\n",
    "            return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "        except ValueError as e :\n",
    "            print(f'Error in document. Error: {e}')\n",
    "            return []\n",
    "        \n",
    "        \n",
    "    def _predict_spacy_verdict(self, row) -> ContentAnalysisResult:\n",
    "        result = ContentAnalysisResult()\n",
    "        count_persons = 0\n",
    "        sensitive_words = find_sensitive_words(row['email_text'])\n",
    "        if len(sensitive_words) > 0:\n",
    "            for word in sensitive_words:\n",
    "                result.piis.append(word)\n",
    "        if row['quids'] and len(row['quids']) > 0: \n",
    "            result.quids = row['quids']\n",
    "        elif row['sensitive'] and len(row['sensitive']) > 0:\n",
    "            result.piis.append(row['sensitive'])\n",
    "        elif row['potentially_sensitive'] and len(row['potentially_sensitive']) > 0:\n",
    "            for ent in row['potentially_sensitive']:\n",
    "                if ent[1] == 'DATE':\n",
    "                    continue\n",
    "                elif ent[1] == 'TIME':\n",
    "                    continue\n",
    "                elif ent[1] == 'QUANTITY':\n",
    "                    continue\n",
    "                elif ent[1] == 'ORDINAL':\n",
    "                    continue\n",
    "                elif ent[1] == 'CARDINAL':\n",
    "                    phone_numbers = find_all_phone_numbers(ent[0])\n",
    "                    credit_cards = find_all_credit_cards(ent[0])\n",
    "                    ssns = find_all_ssn(ent[0])\n",
    "                    for phone_number in phone_numbers:\n",
    "                        result.piis.append(phone_number)\n",
    "                    for credit_card in credit_cards:\n",
    "                        result.piis.append(credit_card)\n",
    "                    for ssn in ssns:\n",
    "                        result.piis.append(ssn)\n",
    "                \n",
    "                #todo maor - think about this, do we want to enter 2 qids in that case? let's see\n",
    "                # elif ent[1] == 'PERSON':\n",
    "                #     count_persons += 1\n",
    "                #     if count_persons > 2:\n",
    "                #         return 'Sensitive'\n",
    "                #     continue\n",
    "        return result\n",
    "    \n",
    "    def analyze(self, row: pd.DataFrame) -> ContentAnalysisResult:\n",
    "        result: ContentAnalysisResult()\n",
    "        copied_row = row.copy()\n",
    "        \n",
    "        if self.software == 'spacy':\n",
    "            result = self._anaylze_spacy(copied_row)\n",
    "        elif self.software == 'presidio':\n",
    "            result = self._analyze_presidio(copied_row)\n",
    "        else:\n",
    "            raise Exception(f'Software {self.software} is not supported')\n",
    "        \n",
    "        print(f'{self.software} based content analysis result: {result}')\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _anaylze_spacy(self, row) -> ContentAnalysisResult:\n",
    "        row['entities'] = self._get_entities(row['email_text'])\n",
    "        unique_entities = set()\n",
    "        for entities in row['entities']:\n",
    "            for ent in entities:\n",
    "                if len(ent) < 2:\n",
    "                    print(f'Entity {ent} is not valid')\n",
    "                    continue\n",
    "                unique_entities.add(ent[1])\n",
    "        row['sensitive'] =  [(ent[0], ent[1]) for ent in row['entities'] if ent[1] in ContentAnalyzer.SENSITIVE]\n",
    "        row['quids'] = [(ent[0], ent[1]) for ent in row['entities'] if ent[1] in ContentAnalyzer.QUIDS]\n",
    "        row['potentially_sensitive'] = [(ent[0], ent[1]) for ent in row['entities'] if ent[1] in ContentAnalyzer.POTENTIALLY_SENSITIVE]\n",
    "        spacy_result = self._predict_spacy_verdict(row)\n",
    "        \n",
    "        return spacy_result\n",
    "    \n",
    "    NON_SENSITIVE = ['EMAIL_ADDRESS', 'URL', 'ORG']\n",
    "    SENSITIVE = ['IP_ADDRESS', 'AU_ACN', 'US_ITIN', 'UK_NHS', 'AU_TFN', 'US_BANK_NUMBER', 'IN_PAN', 'US_DRIVER_LICENSE', 'IN_VEHICLE_REGISTRATION', 'SG_NRIC_FIN', 'US_SSN', 'US_PASSPORT', 'MEDICAL_LICENSE', 'PHONE_NUMBER']\n",
    "    QUASI_SENSITIVE = ['NRP', 'LOCATION', 'PERSON', 'DATE_TIME', 'GPE']\n",
    "    \n",
    "    @staticmethod\n",
    "    def _predict_presidio_verdict(row) -> ContentAnalysisResult:\n",
    "        result = ContentAnalysisResult()\n",
    "        \n",
    "        persons_counter = 0\n",
    "        if row is None:\n",
    "            return result\n",
    "        \n",
    "        email_text = row['email_text']\n",
    "        if email_text is None:\n",
    "            return result\n",
    "        sensitive_words = find_sensitive_words(row['email_text'])\n",
    "        phone_numbers = find_all_phone_numbers(email_text)\n",
    "        credit_cards = find_all_credit_cards(email_text)\n",
    "        ssns = find_all_ssn(email_text)\n",
    "        \n",
    "        for word in sensitive_words:\n",
    "            result.piis.append(word)\n",
    "        for phone_number in phone_numbers:\n",
    "            result.piis.append(phone_number)\n",
    "        for credit_card in credit_cards:\n",
    "            result.piis.append(credit_card)\n",
    "        for ssn in ssns:\n",
    "            result.piis.append(ssn)\n",
    "            \n",
    "    \n",
    "        if row['pii'] is None:\n",
    "            return result\n",
    "        \n",
    "        for pii in row['pii']:\n",
    "            if pii.score < 0.5:\n",
    "                continue\n",
    "            if pii.entity_type.startswith('IN_'):\n",
    "                continue\n",
    "            if pii.entity_type in ContentAnalyzer.NON_SENSITIVE:\n",
    "                continue\n",
    "            if pii.entity_type in ContentAnalyzer.SENSITIVE:\n",
    "                result.piis.append(pii)\n",
    "            if pii.entity_type in ContentAnalyzer.QUASI_SENSITIVE: \n",
    "                # todo maor - think about person\n",
    "                # if pii.entity_type == 'PERSON':\n",
    "                #     persons_counter += 1\n",
    "                #     if persons_counter > 2:\n",
    "                #         return 'Sensitive'\n",
    "                # else:\n",
    "                result.quids.append(pii)\n",
    "    \n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def build_pii_text(self, email_body_text, result):\n",
    "        start = result.start\n",
    "        end = result.end\n",
    "        pii_text = email_body_text[start:end]\n",
    "        return pii_text\n",
    "        \n",
    "    \n",
    "    counter = 0\n",
    "    def analyze_pii(self, email_body_text):\n",
    "        global counter\n",
    "        counter+= 1\n",
    "        if counter % 200 == 0:\n",
    "            print(f'Processed {counter} documents')\n",
    "        pii_list = []\n",
    "        email_body_text = email_body_text[:2000]\n",
    "        \n",
    "        try:\n",
    "            results = self.analyzer.analyze(text=email_body_text, language='en')\n",
    "        except Exception as e:\n",
    "            print(f'Error in document. Error: {e}')\n",
    "            return []\n",
    "        \n",
    "        for result in results:\n",
    "            pii_text = self.build_pii_text(email_body_text, result)\n",
    "            pii = PII(result.entity_type, result.score, pii_text)\n",
    "            pii_list.append(pii)\n",
    "    \n",
    "        return pii_list\n",
    "    \n",
    "\n",
    "\n",
    "    def _analyze_presidio(self, row) -> ContentAnalysisResult:\n",
    "        row['pii'] = row['email_text'].apply(lambda x: self.analyze_pii(x))\n",
    "        presidio_result = self._predict_presidio_verdict(row)\n",
    "        \n",
    "        return presidio_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.219810Z",
     "start_time": "2024-05-11T15:01:17.217240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Efraim\n",
      "[nltk_data]     Yosofov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Efraim\n",
      "[nltk_data]     Yosofov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "import pickle\n",
    "import os\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "class TopicAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model: LdaMulticore = LdaMulticore.load(os.path.join('lda', 'lda_model'))\n",
    "        self.dictionary: Dictionary = Dictionary.load(os.path.join('lda', 'dictionary'))\n",
    "\n",
    "        self.rule_to_topic_before =  {\n",
    "            'None' : [38, 35, 39, 17, 33],\n",
    "            '1.1' : [9, 35, 7, 20, 29,], # legal\n",
    "            '1.2': [1, 9, 7, 18, 20, 35, 24] + [5], # financial data\n",
    "            '1.3': [1, 35, 9, 7, 39] + [5], # business or financial\n",
    "            '2.1': [1, 9, 7, 35, 24, 20], # financial data\n",
    "            '2.2': [1, 9, 18, 7, 17, 16, 24] # business data\n",
    "        }\n",
    "\n",
    "        self.rule_to_topic =  {\n",
    "            'None' : [38, 33, 32, 19, 23, 40, 36],\n",
    "            '1.1' : [2, 20, 9, 35, 22, 25, 34, 5, 18, 37, 31 ], # legal\n",
    "            '1.2': [9, 34, 6, 11, 18, 37, 22, 16, 20, 35] , # financial data\n",
    "            '1.3': [35, 9, 20, 12, 23, 18, 39, 31, 4, 24], # business or financial\n",
    "            '2.1': [9, 2, 20, 34, 18, 25, 22, 24, 35, 37], # financial data\n",
    "            '2.2': [9, 18, 34, 20, 17, 24, 28, 16, 31, 39] # business data\n",
    "        }\n",
    "        \n",
    "    def predict(self, row) -> TopicAnalysisResult:\n",
    "        result = TopicAnalysisResult()\n",
    "        result.is_legal = self.is_legal(row)\n",
    "        result.is_business = self.is_business(row)\n",
    "        result.is_finance = self.is_finance(row)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    \n",
    "    def is_business(self, row):        \n",
    "        text = self.process_text(row)\n",
    "        return self._predict(text, '1.3') | self._predict(text, '2.3')\n",
    "        \n",
    "    \n",
    "    def is_finance(self, row):\n",
    "        text = self.process_text(row)\n",
    "        return self._predict(text, '1.2') | self._predict(text, '2.2') | self._predict(text, '1.3')\n",
    "    \n",
    "    def is_legal(self, row):\n",
    "        text = self.process_text(row)\n",
    "        return self._predict(text, '1.1')\n",
    "    \n",
    "    def process_text(self, row):\n",
    "        subject = row['Subject']\n",
    "        body = row['email_body']\n",
    "        text = self._text_to_bow(subject + \" \" + body)\n",
    "        return text\n",
    "    \n",
    "\n",
    "    def _predict(self, text, label):\n",
    "        if label not in self.rule_to_topic.keys():\n",
    "            return False\n",
    "        \n",
    "        # clean_text = self._text_to_bow(text, self.dictionary)\n",
    "        topics_prob = self._get_top_n_probabilities(text, 4, 0.05)\n",
    "        if topics_prob is None or len(topics_prob) == 0:\n",
    "            return False\n",
    "        \n",
    "        topics = [t[0] for t in topics_prob]\n",
    "        count = len(self._intersecting_list(topics, self.rule_to_topic[label]))\n",
    "        count_none = len(self._intersecting_list(topics, self.rule_to_topic['None']))\n",
    "        if count > 0 and count_none < 3:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    def _text_to_bow(self, text):\n",
    "    # Preprocess the text\n",
    "        preprocessed_text = preprocessing.preprocess_text(text, should_remove_links=True, should_remove_small_words=True, lemmatize=True, should_remove_digits=True) \n",
    "        # Convert the preprocessed text to a bag-of-words using the dictionary\n",
    "        bow = self.dictionary.doc2bow(preprocessed_text.split())\n",
    "        return bow\n",
    "\n",
    "    def _intersecting_list(self, list1, list2):\n",
    "        return list(set(list1) & set(list2))\n",
    "\n",
    "    def _get_probability_debug(self, row):\n",
    "        doc = self._text_to_bow(row['Subject'] + \" \" + row['email_body'])\n",
    "        topics =  self._get_top_n_probabilities(doc, 4, 0.08)\n",
    "        if topics is None:\n",
    "            return None\n",
    "        # if empty\n",
    "        if len(topics) == 0:\n",
    "            return None\n",
    "        return [t[0] for t in topics]\n",
    "\n",
    "    def _get_top_n_probabilities(self, doc, n=5, threshold=0.08):\n",
    "        if not doc:\n",
    "            return None  # Handle empty documents\n",
    "        topic_probs = self.model.get_document_topics(doc, minimum_probability=0)\n",
    "        if not topic_probs:\n",
    "            return None  # Handle cases with no significant topic probability\n",
    "        \n",
    "        topic_probs = [x for x in topic_probs if x[1] > threshold]\n",
    "        return sorted(topic_probs, key=lambda x: x[1], reverse=True)[:n]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:17.453992Z",
     "start_time": "2024-05-11T15:01:17.222690Z"
    }
   },
   "outputs": [],
   "source": [
    "def _only_1_rules_are_violated(static_rule_violations_by_rule_id):\n",
    "    rule_2_prefix = '2.'\n",
    "    \n",
    "    for rule_id in static_rule_violations_by_rule_id.keys():\n",
    "        if rule_2_prefix in rule_id and static_rule_violations_by_rule_id[rule_id]:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "\n",
    "def only_this_rule_violated(static_rule_violations_by_rule_id, rule_id):\n",
    "    return static_rule_violations_by_rule_id[rule_id] == True and sum(static_rule_violations_by_rule_id.values())\n",
    "\n",
    "\n",
    "def _pre_process(mail_row):\n",
    "    subject = mail_row['Subject']\n",
    "    body = mail_row['email_body']\n",
    "    text = preprocessing.preprocess_text(subject + \" \" + body, should_remove_small_words=True, should_remove_digits=False, lemmatize=True)\n",
    "    mail_row['email_text'] = text\n",
    "    return mail_row\n",
    "\n",
    "\n",
    "class Enforcer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.static_analyzer = StaticAnalyzer()\n",
    "        self.topic_analyzer = TopicAnalyzer()\n",
    "        self.content_analyzer = ContentAnalyzer()\n",
    "\n",
    "    def enforce(self, mail_row):\n",
    "        results = []\n",
    "        topic_analysis = self.topic_analyzer.predict(mail_row.copy())\n",
    "\n",
    "        if self.static_analyzer.is_violating_rule_1_1(mail_row):\n",
    "            if topic_analysis.is_legal:\n",
    "                results.append('1.1')\n",
    "        if self.static_analyzer.is_violating_rule_1_2(mail_row):\n",
    "            if topic_analysis.is_finance:\n",
    "                results.append('1.2')\n",
    "        if self.static_analyzer.is_violating_rule_1_3(mail_row):\n",
    "            if topic_analysis.is_business:\n",
    "                results.append('1.3')\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def _enforce(self, mail_row) -> EnforcerResult:\n",
    "        result = EnforcerResult()\n",
    "        copied_row = mail_row.copy()\n",
    "        processed_row = _pre_process(copied_row) # not supoose to be in place, but each model should have its own preprocessing!!!\n",
    "        \n",
    "        static_rule_violations_by_rule_id: {str : bool} = self.analyze_static(processed_row)\n",
    "        content_analysis: ContentAnalysisResult\n",
    "        topic_analysis: TopicAnalysisResult\n",
    "    \n",
    "        # static analysis\n",
    "        if any(static_rule_violations_by_rule_id.values()) is False:\n",
    "            print(f'After static analysis, The Email is not violating any rule and therefore ALLOWED')\n",
    "            return result\n",
    "        \n",
    "        if only_this_rule_violated(static_rule_violations_by_rule_id, rule_id='2.3'):\n",
    "            print(f'Only rule 2.3 is potentially violated. therefore, we can skip topic analysis')\n",
    "            content_analysis: ContentAnalysisResult = self.content_analyzer.analyze(processed_row)\n",
    "            \n",
    "            if content_analysis.is_sensitive('2.3'):\n",
    "                print(f'Email is violating rule 2.3 due to content analysis: {content_analysis} and therefore BLOCKED')\n",
    "                result.violated_rules.append('2.3')\n",
    "            else:\n",
    "                print(f'Email is not violating any rule due to content analysis: {content_analysis} and therefore ALLOWED')\n",
    "            return result\n",
    "        \n",
    "        print(f'Will analyze topic for email, as all rules left required topic analysis')\n",
    "        topic_analysis = self.topic_analyzer.predict(mail_row.copy())\n",
    "        \n",
    "        if _only_1_rules_are_violated(static_rule_violations_by_rule_id):\n",
    "            content_analysis: ContentAnalysisResult = self.content_analyzer.analyze(processed_row) # todo maor - delete\n",
    "            print(f'Only Policy 1# rules are violated statically, can skip content analysis')\n",
    "        else:\n",
    "            print(f'Will analyze content for , as all rules left required content analysis (2)')\n",
    "            content_analysis: ContentAnalysisResult = self.content_analyzer.analyze(processed_row)\n",
    "        \n",
    "        for rule_id, static_rule_violation in static_rule_violations_by_rule_id.items():\n",
    "            if static_rule_violation:\n",
    "                print(f'Email is violating rule {rule_id} due to static analysis. Checking content analysis and topic analysis if needed')\n",
    "            \n",
    "                is_violated_rule_by_content_analysis = self._is_violating_rule_by_content(rule_id, content_analysis)\n",
    "                is_violated_rule_by_topic_analysis = self._is_violating_rule_by_topic(rule_id, topic_analysis)\n",
    "            \n",
    "                if is_violated_rule_by_content_analysis and is_violated_rule_by_topic_analysis:\n",
    "                    print(f'Email is violating rule {rule_id} due to content analysis or topic analysis and therefore BLOCKED')\n",
    "                    result.violated_rules.append(rule_id)\n",
    "                else:\n",
    "                    print(f'Email is not violating rule {rule_id} due to content analysis or topic analysis and therefore ALLOWED')\n",
    "            else:\n",
    "                print(f'Email is not violating rule {rule_id} due to static analysis')\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def analyze_static(self, processed_row) -> {str : bool}:\n",
    "        static_rule_violations_by_rule_id: {str: bool} = {\n",
    "            '1.1': self.static_analyzer.is_violating_rule_1_1(processed_row),\n",
    "            '1.2': self.static_analyzer.is_violating_rule_1_2(processed_row),\n",
    "            '1.3': self.static_analyzer.is_violating_rule_1_3(processed_row),\n",
    "            '2.1': self.static_analyzer.is_violating_rule_2_1(processed_row),\n",
    "            '2.2': self.static_analyzer.is_violating_rule_2_2(processed_row),\n",
    "            '2.3': self.static_analyzer.is_violating_rule_2_3(processed_row)\n",
    "        }\n",
    "        \n",
    "        return static_rule_violations_by_rule_id\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_violating_rule_by_content(rule_id, content_analysis: ContentAnalysisResult):\n",
    "        if '1.' in rule_id:\n",
    "            return False\n",
    "        if rule_id == '2.1' or rule_id == '2.2':\n",
    "            return content_analysis.is_sensitive\n",
    "        elif rule_id == '2.3':\n",
    "            return content_analysis.is_sensitive(rule_id)\n",
    "        else:\n",
    "            raise Exception(f'Rule {rule_id} is not supported')\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _is_violating_rule_by_topic(rule_id, topic_analysis: TopicAnalysisResult):\n",
    "        if rule_id == '1.1':\n",
    "            return topic_analysis.is_legal\n",
    "        elif rule_id == '1.2':\n",
    "            return topic_analysis.is_finance\n",
    "        elif rule_id == '1.3':\n",
    "            return topic_analysis.is_finance or topic_analysis.is_business\n",
    "        elif rule_id == '2.1':\n",
    "            return topic_analysis.is_finance\n",
    "        elif rule_id == '2.2':\n",
    "            return topic_analysis.is_business\n",
    "        elif rule_id == '2.3':\n",
    "            return False\n",
    "        else: \n",
    "            raise Exception(f'Rule {rule_id} is not supported for topic analysis')\n",
    "        \n",
    "enforcer = Enforcer()\n",
    "\n",
    "def classify_mail_extended(mail_row) -> EnforcerResult:\n",
    "    enforcer_results = enforcer.enforce(mail_row)\n",
    "    return enforcer_results\n",
    "\n",
    "def classify_mail(mail_row) -> bool:\n",
    "    enforcer_results = enforcer.enforce(mail_row)\n",
    "    is_allowed = enforcer_results.is_allowed()\n",
    "    verdict_prediction = 'ALLOWED' if is_allowed else 'BLOCKED'\n",
    "    print(f'Email Enforcer results: {enforcer_results}. Will be {verdict_prediction}')\n",
    "    return is_allowed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:19.850951Z",
     "start_time": "2024-05-11T15:01:17.454587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efraim Yosofov\\AppData\\Local\\Temp\\ipykernel_31948\\1050118591.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['is_allowed'] = test_df.apply(lambda row: classify_mail_extended(row), axis=1)\n",
      "C:\\Users\\Efraim Yosofov\\AppData\\Local\\Temp\\ipykernel_31948\\1050118591.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['topics'] = test_df.apply(lambda row: topic_analyzer._get_probability_debug(row), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>Subject</th>\n",
       "      <th>email_body</th>\n",
       "      <th>verdict</th>\n",
       "      <th>violated_rules</th>\n",
       "      <th>is_between_ect_and_ees</th>\n",
       "      <th>is_EU_To_NA</th>\n",
       "      <th>is_c_suit</th>\n",
       "      <th>email_text</th>\n",
       "      <th>is_allowed</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>Mon, 18 Dec 2000 10:11:00 -0800 (PST)</td>\n",
       "      <td>brad.nebergall@enron.com</td>\n",
       "      <td>colleen.koenig@enron.com</td>\n",
       "      <td>Colleen Koenig</td>\n",
       "      <td>Brad Nebergall</td>\n",
       "      <td>Jennifer Medcalf, Mike Rogala</td>\n",
       "      <td></td>\n",
       "      <td>Re: Broadband opportunity with Corestaff</td>\n",
       "      <td>Colleen,\\n\\nThanks for the heads up on this.  We would be pleased to look into this whe=\\nn=20\\n...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1, 2.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Re  Broadband opportunity with Corestaff Colleen,\\n\\nThanks for the heads up on this.  We would ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[32, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>Mon, 18 Dec 2000 10:11:00 -0800 (PST)</td>\n",
       "      <td>brad.nebergall@enron.com</td>\n",
       "      <td>colleen.koenig@enron.com</td>\n",
       "      <td>Colleen Koenig</td>\n",
       "      <td>Brad Nebergall</td>\n",
       "      <td>Jennifer Medcalf, Mike Rogala</td>\n",
       "      <td></td>\n",
       "      <td>Re: Broadband opportunity with Corestaff</td>\n",
       "      <td>Colleen,\\n\\nThanks for the heads up on this.  We would be pleased to look into this whe=\\nn=20\\n...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1, 2.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Re  Broadband opportunity with Corestaff Colleen,\\n\\nThanks for the heads up on this.  We would ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[32, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10309</th>\n",
       "      <td>Tue, 23 Jan 2001 00:44:00 -0800 (PST)</td>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "      <td>shanna.husser@enron.com</td>\n",
       "      <td>Shanna Husser</td>\n",
       "      <td>Eric Bass</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ticketless Itinerary</td>\n",
       "      <td>why did i get this?\\n---------------------- Forwarded by Eric Bass/HOU/ECT on 01/23/2001 08:43 A...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1, 2.1, 2.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Ticketless Itinerary why did i get this?\\n              Ticketless Itinerary\\n\\n\\n\\nThis e mail ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[14, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>Tue, 24 Oct 2000 03:22:00 -0700 (PDT)</td>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "      <td>shanna.husser@enron.com</td>\n",
       "      <td>Shanna Husser</td>\n",
       "      <td>Eric Bass</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Re: It could happen!!!</td>\n",
       "      <td>---------------------- Forwarded by Eric Bass/HOU/ECT on 10/24/2000 10:21 AM \\n-----------------...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Re  It could happen!!!               Re  It could happen!!!  \\n\\nI guess you just summed up the ...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>[38, 35, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10471</th>\n",
       "      <td>Tue, 24 Oct 2000 02:57:00 -0700 (PDT)</td>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "      <td>shanna.husser@enron.com</td>\n",
       "      <td>Shanna Husser</td>\n",
       "      <td>Eric Bass</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Re: It could happen!!!</td>\n",
       "      <td>Thought you might like Superfan's comments.\\n---------------------- Forwarded by Eric Bass/HOU/E...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Re  It could happen!!! Thought you might like Superfan's comments.\\n              Re  It could h...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>[38, 35, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211731</th>\n",
       "      <td>Wed, 9 Feb 2000 01:23:00 -0800 (PST)</td>\n",
       "      <td>michael.brown@enron.com</td>\n",
       "      <td>ted.murphy@enron.com</td>\n",
       "      <td>Ted Murphy</td>\n",
       "      <td>Michael R Brown</td>\n",
       "      <td>Steve W Young, Fernley Dyson, William S Bradford, John Sherriff, Vince J Kaminski, Rick Buy</td>\n",
       "      <td></td>\n",
       "      <td>Re: Credit Trading brought to you by Bryan Seyfried</td>\n",
       "      <td>I am happy that the legal issues have been addressed and discussed with Bryan \\nand John and I w...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Re  Credit Trading brought to you by Bryan Seyfried I am happy that the legal issues have been a...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>[34, 9, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371281</th>\n",
       "      <td>Thu, 30 Aug 2001 07:54:21 -0700 (PDT)</td>\n",
       "      <td>elliot.mainzer@enron.com</td>\n",
       "      <td>richard.ring@enron.com, stacey.bolton@enron.com, jesse.bryson@enron.com, \\n\\tjennifer.thome@enro...</td>\n",
       "      <td>Ring, Richard &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rring&gt;, Bolton, Stacey &lt;/O=ENRON/OU=NA/CN=RECIPIE...</td>\n",
       "      <td>Mainzer, Elliot &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=EMAINZE&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Renewable Power Desk Activities</td>\n",
       "      <td>Greetings all --\\nGiven my rather other-world state on yesterday's conference call, I wanted =\\n...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1, 2.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Renewable Power Desk Activities Greetings all   \\nGiven my rather other world state on yesterday...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>[28, 9, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371507</th>\n",
       "      <td>Tue, 25 Sep 2001 13:13:37 -0700 (PDT)</td>\n",
       "      <td>jesse.bryson@enron.com</td>\n",
       "      <td>richard.ring@enron.com</td>\n",
       "      <td>Ring, Richard &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rring&gt;</td>\n",
       "      <td>Bryson, Jesse &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=JBRYSON&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>FW: Price request</td>\n",
       "      <td>Here you are?.\\n\\n -----Original Message-----\\nFrom: \\tVan houten, Maria  \\nSent:\\tTuesday, Sept...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Price request Here you are?.\\n\\n      Original Message     \\nFrom  \\tVan houten, Maria  \\nSent...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>[22, 25, 1, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385844</th>\n",
       "      <td>Tue, 15 May 2001 07:59:00 -0700 (PDT)</td>\n",
       "      <td>elizabeth.sager@enron.com</td>\n",
       "      <td>richard.ring@enron.com</td>\n",
       "      <td>Richard Ring</td>\n",
       "      <td>Elizabeth Sager</td>\n",
       "      <td>Joe Gordon</td>\n",
       "      <td></td>\n",
       "      <td>Re: EESI &amp; EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes)</td>\n",
       "      <td>Here are proposed revisions.  Give me a call after you have reviewed. Thanks\\n\\n\\n\\n\\n\\n\\n\\tRich...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Re  EESI &amp; EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes) Here are proposed revi...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>[20, 22, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385845</th>\n",
       "      <td>Tue, 15 May 2001 09:03:00 -0700 (PDT)</td>\n",
       "      <td>elizabeth.sager@enron.com</td>\n",
       "      <td>richard.ring@enron.com</td>\n",
       "      <td>Richard Ring</td>\n",
       "      <td>Elizabeth Sager</td>\n",
       "      <td>Joe Gordon</td>\n",
       "      <td></td>\n",
       "      <td>Re: EESI &amp; EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes)</td>\n",
       "      <td>OK with me - go ahead and prepare final version and then Joe and I will meet \\nwith EPMI to trad...</td>\n",
       "      <td>BLOCK</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Re  EESI &amp; EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes) OK with me   go ahead ...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>[20, 22, 25, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Date                       From  \\\n",
       "3942    Mon, 18 Dec 2000 10:11:00 -0800 (PST)   brad.nebergall@enron.com   \n",
       "4954    Mon, 18 Dec 2000 10:11:00 -0800 (PST)   brad.nebergall@enron.com   \n",
       "10309   Tue, 23 Jan 2001 00:44:00 -0800 (PST)        eric.bass@enron.com   \n",
       "10470   Tue, 24 Oct 2000 03:22:00 -0700 (PDT)        eric.bass@enron.com   \n",
       "10471   Tue, 24 Oct 2000 02:57:00 -0700 (PDT)        eric.bass@enron.com   \n",
       "...                                       ...                        ...   \n",
       "211731   Wed, 9 Feb 2000 01:23:00 -0800 (PST)    michael.brown@enron.com   \n",
       "371281  Thu, 30 Aug 2001 07:54:21 -0700 (PDT)   elliot.mainzer@enron.com   \n",
       "371507  Tue, 25 Sep 2001 13:13:37 -0700 (PDT)     jesse.bryson@enron.com   \n",
       "385844  Tue, 15 May 2001 07:59:00 -0700 (PDT)  elizabeth.sager@enron.com   \n",
       "385845  Tue, 15 May 2001 09:03:00 -0700 (PDT)  elizabeth.sager@enron.com   \n",
       "\n",
       "                                                                                                         To  \\\n",
       "3942                                                                               colleen.koenig@enron.com   \n",
       "4954                                                                               colleen.koenig@enron.com   \n",
       "10309                                                                               shanna.husser@enron.com   \n",
       "10470                                                                               shanna.husser@enron.com   \n",
       "10471                                                                               shanna.husser@enron.com   \n",
       "...                                                                                                     ...   \n",
       "211731                                                                                 ted.murphy@enron.com   \n",
       "371281  richard.ring@enron.com, stacey.bolton@enron.com, jesse.bryson@enron.com, \\n\\tjennifer.thome@enro...   \n",
       "371507                                                                               richard.ring@enron.com   \n",
       "385844                                                                               richard.ring@enron.com   \n",
       "385845                                                                               richard.ring@enron.com   \n",
       "\n",
       "                                                                                                       X-To  \\\n",
       "3942                                                                                         Colleen Koenig   \n",
       "4954                                                                                         Colleen Koenig   \n",
       "10309                                                                                         Shanna Husser   \n",
       "10470                                                                                         Shanna Husser   \n",
       "10471                                                                                         Shanna Husser   \n",
       "...                                                                                                     ...   \n",
       "211731                                                                                           Ted Murphy   \n",
       "371281  Ring, Richard </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rring>, Bolton, Stacey </O=ENRON/OU=NA/CN=RECIPIE...   \n",
       "371507                                                Ring, Richard </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rring>   \n",
       "385844                                                                                         Richard Ring   \n",
       "385845                                                                                         Richard Ring   \n",
       "\n",
       "                                                           X-From  \\\n",
       "3942                                               Brad Nebergall   \n",
       "4954                                               Brad Nebergall   \n",
       "10309                                                   Eric Bass   \n",
       "10470                                                   Eric Bass   \n",
       "10471                                                   Eric Bass   \n",
       "...                                                           ...   \n",
       "211731                                            Michael R Brown   \n",
       "371281  Mainzer, Elliot </O=ENRON/OU=NA/CN=RECIPIENTS/CN=EMAINZE>   \n",
       "371507    Bryson, Jesse </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JBRYSON>   \n",
       "385844                                            Elizabeth Sager   \n",
       "385845                                            Elizabeth Sager   \n",
       "\n",
       "                                                                                               X-cc  \\\n",
       "3942                                                                  Jennifer Medcalf, Mike Rogala   \n",
       "4954                                                                  Jennifer Medcalf, Mike Rogala   \n",
       "10309                                                                                                 \n",
       "10470                                                                                                 \n",
       "10471                                                                                                 \n",
       "...                                                                                             ...   \n",
       "211731  Steve W Young, Fernley Dyson, William S Bradford, John Sherriff, Vince J Kaminski, Rick Buy   \n",
       "371281                                                                                                \n",
       "371507                                                                                                \n",
       "385844                                                                                   Joe Gordon   \n",
       "385845                                                                                   Joe Gordon   \n",
       "\n",
       "       X-bcc  \\\n",
       "3942           \n",
       "4954           \n",
       "10309          \n",
       "10470          \n",
       "10471          \n",
       "...      ...   \n",
       "211731         \n",
       "371281         \n",
       "371507         \n",
       "385844         \n",
       "385845         \n",
       "\n",
       "                                                                          Subject  \\\n",
       "3942                                     Re: Broadband opportunity with Corestaff   \n",
       "4954                                     Re: Broadband opportunity with Corestaff   \n",
       "10309                                                        Ticketless Itinerary   \n",
       "10470                                                      Re: It could happen!!!   \n",
       "10471                                                      Re: It could happen!!!   \n",
       "...                                                                           ...   \n",
       "211731                        Re: Credit Trading brought to you by Bryan Seyfried   \n",
       "371281                                            Renewable Power Desk Activities   \n",
       "371507                                                          FW: Price request   \n",
       "385844  Re: EESI & EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes)   \n",
       "385845  Re: EESI & EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes)   \n",
       "\n",
       "                                                                                                 email_body  \\\n",
       "3942    Colleen,\\n\\nThanks for the heads up on this.  We would be pleased to look into this whe=\\nn=20\\n...   \n",
       "4954    Colleen,\\n\\nThanks for the heads up on this.  We would be pleased to look into this whe=\\nn=20\\n...   \n",
       "10309   why did i get this?\\n---------------------- Forwarded by Eric Bass/HOU/ECT on 01/23/2001 08:43 A...   \n",
       "10470   ---------------------- Forwarded by Eric Bass/HOU/ECT on 10/24/2000 10:21 AM \\n-----------------...   \n",
       "10471   Thought you might like Superfan's comments.\\n---------------------- Forwarded by Eric Bass/HOU/E...   \n",
       "...                                                                                                     ...   \n",
       "211731  I am happy that the legal issues have been addressed and discussed with Bryan \\nand John and I w...   \n",
       "371281  Greetings all --\\nGiven my rather other-world state on yesterday's conference call, I wanted =\\n...   \n",
       "371507  Here you are?.\\n\\n -----Original Message-----\\nFrom: \\tVan houten, Maria  \\nSent:\\tTuesday, Sept...   \n",
       "385844  Here are proposed revisions.  Give me a call after you have reviewed. Thanks\\n\\n\\n\\n\\n\\n\\n\\tRich...   \n",
       "385845  OK with me - go ahead and prepare final version and then Joe and I will meet \\nwith EPMI to trad...   \n",
       "\n",
       "       verdict   violated_rules  is_between_ect_and_ees  is_EU_To_NA  \\\n",
       "3942     BLOCK       [1.1, 2.1]                    True        False   \n",
       "4954     BLOCK       [1.1, 2.1]                    True        False   \n",
       "10309    BLOCK  [1.1, 2.1, 2.2]                    True        False   \n",
       "10470    BLOCK            [1.1]                    True        False   \n",
       "10471    BLOCK            [1.1]                    True        False   \n",
       "...        ...              ...                     ...          ...   \n",
       "211731   BLOCK            [1.1]                    True        False   \n",
       "371281   BLOCK       [1.1, 2.1]                    True        False   \n",
       "371507   BLOCK            [1.1]                    True        False   \n",
       "385844   BLOCK            [1.1]                    True        False   \n",
       "385845   BLOCK            [1.1]                    True        False   \n",
       "\n",
       "        is_c_suit  \\\n",
       "3942        False   \n",
       "4954        False   \n",
       "10309        True   \n",
       "10470        True   \n",
       "10471        True   \n",
       "...           ...   \n",
       "211731      False   \n",
       "371281      False   \n",
       "371507      False   \n",
       "385844      False   \n",
       "385845      False   \n",
       "\n",
       "                                                                                                 email_text  \\\n",
       "3942    Re  Broadband opportunity with Corestaff Colleen,\\n\\nThanks for the heads up on this.  We would ...   \n",
       "4954    Re  Broadband opportunity with Corestaff Colleen,\\n\\nThanks for the heads up on this.  We would ...   \n",
       "10309   Ticketless Itinerary why did i get this?\\n              Ticketless Itinerary\\n\\n\\n\\nThis e mail ...   \n",
       "10470   Re  It could happen!!!               Re  It could happen!!!  \\n\\nI guess you just summed up the ...   \n",
       "10471   Re  It could happen!!! Thought you might like Superfan's comments.\\n              Re  It could h...   \n",
       "...                                                                                                     ...   \n",
       "211731  Re  Credit Trading brought to you by Bryan Seyfried I am happy that the legal issues have been a...   \n",
       "371281  Renewable Power Desk Activities Greetings all   \\nGiven my rather other world state on yesterday...   \n",
       "371507    Price request Here you are?.\\n\\n      Original Message     \\nFrom  \\tVan houten, Maria  \\nSent...   \n",
       "385844  Re  EESI & EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes) Here are proposed revi...   \n",
       "385845  Re  EESI & EPMI Confirmation Agreement (NYSEG PJM Renewable\\n Attributes) OK with me   go ahead ...   \n",
       "\n",
       "       is_allowed           topics  \n",
       "3942           []         [32, 29]  \n",
       "4954           []         [32, 29]  \n",
       "10309          []         [14, 39]  \n",
       "10470       [1.1]      [38, 35, 2]  \n",
       "10471       [1.1]      [38, 35, 2]  \n",
       "...           ...              ...  \n",
       "211731      [1.1]       [34, 9, 5]  \n",
       "371281      [1.1]      [28, 9, 35]  \n",
       "371507      [1.1]  [22, 25, 1, 20]  \n",
       "385844      [1.1]      [20, 22, 6]  \n",
       "385845      [1.1]  [20, 22, 25, 5]  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic_analyzer = TopicAnalyzer()\n",
    "\n",
    "\n",
    "test_df = enron_df[enron_df['violated_rules'].apply(lambda x: '1.1' in x)]\n",
    "test_df['is_allowed'] = test_df.apply(lambda row: classify_mail_extended(row), axis=1)\n",
    "# test_df['topics'] = test_df.apply(lambda row: topic_analyzer._get_probability_debug(row), axis=1)\n",
    "# test_df[test_df['is_between_ect_and_ees'] == True].head(100)\n",
    "\n",
    "# todo maor - Print accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed attachments\n",
      "parsed contacts\n",
      "removed links\n",
      "removed foward text\n",
      "filled nan values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\private\\Cyber and Machine learning\\Assignments\\cyber-ai\\preprocessing.py:140: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  enron_df['email_text'].fillna(' ', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed email headers\n",
      "removed small words\n",
      "lemmatized\n"
     ]
    }
   ],
   "source": [
    "model, dictionary = topic_analyzer.model, topic_analyzer.dictionary\n",
    "enron_df['email_text'] = enron_df['Subject'] + \" \" + enron_df['email_body']\n",
    "preprocessing.data_cleaning(enron_df, True)\n",
    "enron_df['tokens'] = enron_df['email_text'].apply(lambda x: x.split())\n",
    "enron_df['bow'] = enron_df['tokens'].apply(dictionary.doc2bow)\n",
    "\n",
    "bow_corpus = enron_df[enron_df['bow'].map(len) > 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:19.852680Z",
     "start_time": "2024-05-11T15:01:19.851561Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Visualize the topics\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m vis \u001b[38;5;241m=\u001b[39m gensimvis\u001b[38;5;241m.\u001b[39mprepare(model, \u001b[43mbow_corpus\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbow\u001b[39m\u001b[38;5;124m'\u001b[39m], dictionary)\n\u001b[0;32m      6\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mdisplay(vis)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bow_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "vis = gensimvis.prepare(model, bow_corpus['bow'], dictionary)\n",
    "pyLDAvis.display(vis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
